{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b3eb5e6-2476-4b97-a0bf-304847b4c83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa2b47ade10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import is_flash_attn_2_available\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import json\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd16d255-3252-4d0f-9b1b-e7c0ea85c6a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def check_gpu(step):\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"{step}: GPU memory used: {info.used // 1024**2} MB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df44f2c5-6f19-44ec-a5a7-b82164330a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def D(obj):\n",
    "    if isinstance(obj, tuple):\n",
    "        print(len(obj))\n",
    "    elif isinstance(obj, torch.Tensor):\n",
    "        print(obj.shape)\n",
    "        display(obj)\n",
    "    else:\n",
    "        display(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26136ca-dd13-48d6-a6d5-b6c1106df5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961fc3faaff04fda9023c0f9bf48f3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n",
      "model init: GPU memory used: 7813 MB.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True,\n",
    "    use_cache=True,\n",
    "    # attn_implementation='flash_attention_2',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print('device', device)\n",
    "\n",
    "check_gpu('model init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37365508-011a-47db-96af-2617ad2f759e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_candidates = 16\n",
    "max_new_tokens = 100\n",
    "batch_size = 8\n",
    "p_falloff = 0.5 # UNIMPLEMENTED\n",
    "prune_similar_sequences = True # UNIMPLEMENTED\n",
    "prune_similar_branches = True # UNIMPLEMENTED\n",
    "prune_similar_embeddings = True # UNIMPLEMENTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a537c32-7c28-449a-b82a-37da1a247416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0],\n",
       "        [    0,     0,     0,  ...,     0,     0,     0]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates init: GPU memory used: 7843 MB.\n"
     ]
    }
   ],
   "source": [
    "def init_candidates(text: str):\n",
    "    prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt')\n",
    "\n",
    "    max_total_tokens = inputs.input_ids.shape[1] + max_new_tokens\n",
    "\n",
    "    # (max_candidates, max_total_tokens)\n",
    "    candidates = torch.zeros((max_candidates, max_total_tokens), dtype=torch.long, device=device)\n",
    "    # (max_candidates, max_total_tokens)\n",
    "    candidate_masks = torch.zeros((max_candidates, max_total_tokens), dtype=torch.bool, device=device)\n",
    "    # (max_candidates)\n",
    "    candidate_parents = torch.zeros((max_candidates), dtype=torch.long, device=device)\n",
    "    # (max_candidates)\n",
    "    candidate_logprobs = torch.zeros((max_candidates), dtype=torch.float32, device=device)\n",
    "\n",
    "    candidates[0, :inputs.input_ids.shape[1]] = inputs.input_ids\n",
    "    candidate_masks[0, :inputs.input_ids.shape[1]] = inputs.attention_mask\n",
    "    candidate_parents[0] = 0\n",
    "    candidate_logprobs[0] = 0.0\n",
    "\n",
    "    return candidates, candidate_masks, candidate_parents, candidate_logprobs\n",
    "\n",
    "candidates, candidate_masks, candidate_parents, candidate_logprobs = init_candidates('What is the cutest dog?')\n",
    "D(candidates)\n",
    "D(candidate_masks)\n",
    "D(candidate_parents)\n",
    "D(candidate_logprobs)\n",
    "\n",
    "check_gpu('candidates init')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fdc2ad3-30dd-4f3a-9f7c-32447b083181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 7843 MB.\n",
      "torch.Size([8, 112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  5700,   342, 11203, 29973, 29871,\n",
       "         32007, 32001,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0],\n",
       "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch views made: GPU memory used: 7843 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 112, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8281,  1.3594, -0.4043,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 4.2812,  9.6875, 10.1250,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 6.1562,  2.9688,  3.8906,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 4.2500,  0.2734,  0.3008,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 5.3750,  1.3203,  2.7969,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 5.6562,  1.4062,  3.4844,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch forward run: GPU memory used: 14455 MB.\n",
      "batch outputs deleted: GPU memory used: 14455 MB.\n",
      "torch.Size([8, 112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False],\n",
       "        [False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch views made: GPU memory used: 14455 MB.\n",
      "torch.Size([8, 112, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 2.7188, -0.4512, -0.9805,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0', grad_fn=<ToCopyBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch forward run: GPU memory used: 14455 MB.\n",
      "batch outputs deleted: GPU memory used: 14455 MB.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all batches run: GPU memory used: 14455 MB.\n"
     ]
    }
   ],
   "source": [
    "def infer(candidates, candidate_masks, candidate_parents, candidate_logprobs):\n",
    "    batches = (max_candidates + batch_size - 1) // batch_size  # Round up to nearest whole number of batches\n",
    "    \n",
    "    check_gpu('infer start')\n",
    "    for i in range(0, batches, 1):\n",
    "        batch_candidates = candidates[i * batch_size:(i + 1) * batch_size]\n",
    "        D(batch_candidates)\n",
    "        batch_candidate_masks = candidate_masks[i * batch_size:(i + 1) * batch_size]\n",
    "        D(batch_candidate_masks)\n",
    "        \n",
    "        check_gpu('batch views made')\n",
    "        \n",
    "        batch_outputs = model(input_ids=batch_candidates, attention_mask=batch_candidate_masks)\n",
    "        D(batch_outputs.logits)\n",
    "        \n",
    "        # Possibly turn off caching to save memory here?\n",
    "        check_gpu('batch forward run')\n",
    "        \n",
    "        del batch_outputs\n",
    "        \n",
    "        check_gpu('batch outputs deleted')\n",
    "\n",
    "outputs = infer(candidates, candidate_masks, candidate_parents, candidate_logprobs)\n",
    "D(outputs)\n",
    "\n",
    "check_gpu('all batches run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca8be196-eac7-459a-bcf9-64fe0979ace4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3470924711.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"logits of shape (batch_size,\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def top_p_tokens(logits, top_p=0.9):\n",
    "    \"\"\"logits of shape (batch_size, vocab_size)\"\"\"\n",
    "    sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "    probs = F.softmax(sorted_logits, dim=-1)\n",
    "    cum_probs = torch.cumsum(probs, dim=-1)\n",
    "    # Create tensor of bools indicating which indices are cumulatively less than top_p\n",
    "    sorted_keep_indices = cum_probs < 0.9\n",
    "    # Keep the last element that went over top_p\n",
    "    sorted_keep_indices[1:] = sorted_keep_indices[:-1].clone()\n",
    "    sorted_keep_indices[0] = 1  # Always keep the first element\n",
    "    keep_toks = sorted_indices[sorted_keep_indices]\n",
    "    keep_probs = probs[sorted_keep_indices]\n",
    "    return keep_toks, keep_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3bba1-ed50-4c27-8d71-8912665bd666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def candidates_generator(text: str):\n",
    "#     print(text)\n",
    "#     candidates, candidate_masks, candidate_parents, candidate_logprobs = _init_candidates(text)\n",
    "\n",
    "#     return candidates, candidate_masks, candidate_parents, candidate_logprobs\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
