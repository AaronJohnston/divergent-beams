{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4c5a58-9019-4a7e-a39a-075947c7ebbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.5.9.post1)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.41.1)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.30.1)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn) (2.1.0)\n",
      "Requirement already satisfied: einops in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (3.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fdcff877fb34f5fac29dcc88067aab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn_2 available: True\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn transformers accelerate\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "print(\"flash_attn_2 available:\", is_flash_attn_2_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c2648d-ecc7-48cd-8378-923aca9dc2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|user|> What is the closest star to the Sun? "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|end|><|assistant|> The closest star to the Sun is Proxima Centauri. It is part of the Alpha Centauri star system, which also includes Alpha Centauri A and Alpha Centauri B. Proxima Centauri is approximately 4.24 light-years away from the Sun. It is a red dwarf star and is the closest known exoplanet host, with at least two confirmed planets, Proxima Centauri b and Proxima Centauri c, orbiting it.<|end|>\n",
      "== took 0:00:04.800694 (113 toks: 0:00:00.042484/tok; 23.53826175902905 tps) ==\n",
      "<s><|user|> What is the difference between hue, saturation, and value? <|end|><|assistant|> Hue, saturation, and value are three components of the color model known as HSV (Hue, Saturation, Value), which is also referred to as HSB (Hue, Saturation, Brightness) in some contexts. These components are used to describe and manipulate colors in digital imaging and color theory. Here's a breakdown of each component:\n",
      "\n",
      "1. Hue: Hue refers to the color itself, or the dominant wavelength of light that determines the color we perceive. It is measured in degrees on a color wheel, with 0° representing red, 120° representing green, and 240° representing blue. Hue is the attribute that allows us to distinguish between different colors, such as red, blue, or yellow.\n",
      "\n",
      "2. Saturation: Saturation, also known as chroma or intensity, refers to the purity or intensity of a color. It measures the degree to which a color is diluted with white or gray. A fully saturated color is vivid and intense, while a less saturated color appears more muted or washed out. Saturation is typically measured on a scale from 0% (completely desaturated, or gray) to 100% (fully saturated).\n",
      "\n",
      "3. Value: Value, also known as brightness or lightness, refers to the relative lightness or darkness of a color. It measures the amount of light that a color reflects or emits. A higher value indicates a lighter color, while a lower value indicates a darker color. Value is typically measured on a scale from 0% (completely black) to 100% (fully white).\n",
      "\n",
      "In summary, hue determines the color itself, saturation determines the intensity or purity of the color, and value determines the lightness or darkness of the color. These three components can be used to create a wide range of colors and shades, and they are particularly useful in digital image processing and design applications.<|end|>\n",
      "== took 0:00:16.846590 (442 toks: 0:00:00.038114/tok; 26.23676310136528 tps) ==\n",
      "<s><|user|> Where is Waldo? <|end|><|assistant|> I'm unable to assist with that. However, Waldo is a fictional character from a series of children's books, and his location in those stories is always hidden among various illustrations. If you're referring to a different context, please provide more details.<|end|>\n",
      "== took 0:00:02.136611 (56 toks: 0:00:00.038154/tok; 26.20972942645911 tps) ==\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm unable to assist with that. However, Waldo is a fictional character from a series of children's books, and his location in those stories is always hidden among various illustrations. If you're referring to a different context, please provide more details.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen(text, preview=True):\n",
    "    duration_start = time.perf_counter()\n",
    "    prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        tokens,\n",
    "        max_new_tokens=1024,\n",
    "        return_dict_in_generate=True,\n",
    "        streamer=streamer if preview else None,\n",
    "    )\n",
    "    output_tokens = outputs.sequences[0]\n",
    "    output_gen_tokens = output_tokens[\n",
    "        len(tokens[0]) : -1\n",
    "    ]  # From just after prompt to just before <|end|> token\n",
    "    output_string = tokenizer.decode(output_gen_tokens)\n",
    "    duration_seconds = time.perf_counter() - duration_start\n",
    "    print(\n",
    "        \"== took {} ({} toks: {}/tok; {} tps) ==\".format(\n",
    "            timedelta(seconds=duration_seconds),\n",
    "            len(output_gen_tokens),\n",
    "            timedelta(seconds=duration_seconds / len(output_gen_tokens)),\n",
    "            len(output_gen_tokens) / duration_seconds,\n",
    "        )\n",
    "    )\n",
    "    del tokens, outputs, output_tokens, output_gen_tokens\n",
    "    return output_string\n",
    "\n",
    "\n",
    "gen(\"What is the closest star to the Sun?\")\n",
    "gen(\"What is the difference between hue, saturation, and value?\")\n",
    "gen(\"Where is Waldo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c580a935-ef4d-40db-b6ff-5b47d844786e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|user|> Please generate an example conversation between participant1 and participant2 about frogs. Make it last 20 utterances and have a follow-up. Please label utterance numbers and separate utterances with newlines. <|end|><|assistant|> 1. Participant1: Hey, have you ever been fascinated by frogs?\n",
      "2. Participant2: Actually, yes! I find them quite interesting. Why do you ask?\n",
      "3. Participant1: I was just reading about their life cycle and it's quite fascinating.\n",
      "4. Participant2: Oh, I'd love to hear more about it. What did you learn?\n",
      "5. Participant1: Well, did you know that frogs start their life as eggs?\n",
      "6. Participant2: Yes, I've heard about that. The eggs hatch into tadpoles, right?\n",
      "7. Participant1: Exactly! Tadpoles live in water and breathe through gills.\n",
      "8. Participant2: That's so cool! And then they undergo metamorphosis to become adult frogs.\n",
      "9. Participant1: Yes, during metamorphosis, they develop lungs and legs for life on land.\n",
      "10. Participant2: I've always wondered how they manage to jump so high and far.\n",
      "11. Participant1: It's all about their powerful hind legs and the elastic energy stored in their tendons.\n",
      "12. Participant2: That's amazing! I've also heard that frogs have a unique way of communicating.\n",
      "13. Participant1: You're right! They use vocalizations, body language, and even chemical signals.\n",
      "14. Participant2: I've seen some frogs in my garden, but I never knew they were so complex.\n",
      "15. Participant1: They're definitely fascinating creatures. Did you know that some frogs can change their skin color?\n",
      "16. Participant2: Really? That's incredible! I'd love to see that in person someday.\n",
      "17. Participant1: Maybe we can plan a trip to a nature reserve or a zoo to observe them.\n",
      "18. Participant2: That sounds like a great idea! I'd love to learn more about frogs in their natural habitat.\n",
      "19. Participant1: Let's do it! We can also look for local frog enthusiasts or experts to join us.\n",
      "20. Participant2: I'm excited! This will be a fun and educational adventure.\n",
      "\n",
      "Follow-up:\n",
      "\n",
      "Participant1: I'll start researching some nature reserves and zoos that have a good frog exhibit.\n",
      "Participant2: Great! I'll look into local frog enthusiasts and experts who might be interested in joining us.\n",
      "Participant1: Perfect! Let's reconvene next week and share our findings.\n",
      "Participant2: Sounds like a plan. I can't wait to dive deeper into the world of frogs with you!<|end|>\n",
      "== took 0:00:25.569551 (665 toks: 0:00:00.038450/tok; 26.007495783991562 tps) ==\n"
     ]
    }
   ],
   "source": [
    "conv = gen(\n",
    "    \"Please generate an example conversation between participant1 and participant2 about frogs. Make it last 20 utterances and have a follow-up. Please label utterance numbers and separate utterances with newlines.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11272aa-b340-44df-9859-dbc82b6b3287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><|user|> Summarize the following conversation between two participants. Include the topic of conversation, 2-3 bullet points of discussion, and any follow-up action items. Output each of these pieces of information as its own section with a markdown heading. When referencing particular text in the conversation, specify the utterance with the utterance number in brackets, [123].\n",
      "    \n",
      "    1. Participant1: Hey, have you ever been fascinated by frogs?\n",
      "2. Participant2: Actually, yes! I find them quite interesting. Why do you ask?\n",
      "3. Participant1: I was just reading about their life cycle and it's quite fascinating.\n",
      "4. Participant2: Oh, I'd love to hear more about it. What did you learn?\n",
      "5. Participant1: Well, did you know that frogs start their life as eggs?\n",
      "6. Participant2: Yes, I've heard about that. The eggs hatch into tadpoles, right?\n",
      "7. Participant1: Exactly! Tadpoles live in water and breathe through gills.\n",
      "8. Participant2: That's so cool! And then they undergo metamorphosis to become adult frogs.\n",
      "9. Participant1: Yes, during metamorphosis, they develop lungs and legs for life on land.\n",
      "10. Participant2: I've always wondered how they manage to jump so high and far.\n",
      "11. Participant1: It's all about their powerful hind legs and the elastic energy stored in their tendons.\n",
      "12. Participant2: That's amazing! I've also heard that frogs have a unique way of communicating.\n",
      "13. Participant1: You're right! They use vocalizations, body language, and even chemical signals.\n",
      "14. Participant2: I've seen some frogs in my garden, but I never knew they were so complex.\n",
      "15. Participant1: They're definitely fascinating creatures. Did you know that some frogs can change their skin color?\n",
      "16. Participant2: Really? That's incredible! I'd love to see that in person someday.\n",
      "17. Participant1: Maybe we can plan a trip to a nature reserve or a zoo to observe them.\n",
      "18. Participant2: That sounds like a great idea! I'd love to learn more about frogs in their natural habitat.\n",
      "19. Participant1: Let's do it! We can also look for local frog enthusiasts or experts to join us.\n",
      "20. Participant2: I'm excited! This will be a fun and educational adventure.\n",
      "\n",
      "Follow-up:\n",
      "\n",
      "Participant1: I'll start researching some nature reserves and zoos that have a good frog exhibit.\n",
      "Participant2: Great! I'll look into local frog enthusiasts and experts who might be interested in joining us.\n",
      "Participant1: Perfect! Let's reconvene next week and share our findings.\n",
      "Participant2: Sounds like a plan. I can't wait to dive deeper into the world of frogs with you!\n",
      " <|end|><|assistant|> # Conversation Topic\n",
      "- Participants discussing the fascinating aspects of frogs, including their life cycle, abilities, and communication methods.\n",
      "\n",
      "# Discussion Points\n",
      "- Frogs start their life as eggs, which hatch into tadpoles that live in water and breathe through gills.\n",
      "- During metamorphosis, tadpoles develop lungs and legs to adapt to life on land.\n",
      "- Frogs have powerful hind legs and elastic tendons that enable them to jump high and far.\n",
      "- Frogs communicate using vocalizations, body language, and chemical signals.\n",
      "- Some frogs can change their skin color.\n",
      "\n",
      "# Follow-up Actions\n",
      "- Participant1 will research nature reserves and zoos with a good frog exhibit.\n",
      "- Participant2 will look into local frog enthusiasts and experts who might be interested in joining the trip.\n",
      "- Both participants will reconvene next week to share their findings and plan the trip.<|end|>\n",
      "== took 0:00:09.279508 (223 toks: 0:00:00.041612/tok; 24.031446145179824 tps) ==\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Conversation Topic\\n- Participants discussing the fascinating aspects of frogs, including their life cycle, abilities, and communication methods.\\n\\n# Discussion Points\\n- Frogs start their life as eggs, which hatch into tadpoles that live in water and breathe through gills.\\n- During metamorphosis, tadpoles develop lungs and legs to adapt to life on land.\\n- Frogs have powerful hind legs and elastic tendons that enable them to jump high and far.\\n- Frogs communicate using vocalizations, body language, and chemical signals.\\n- Some frogs can change their skin color.\\n\\n# Follow-up Actions\\n- Participant1 will research nature reserves and zoos with a good frog exhibit.\\n- Participant2 will look into local frog enthusiasts and experts who might be interested in joining the trip.\\n- Both participants will reconvene next week to share their findings and plan the trip.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Summarize the following conversation between two participants. Include the topic of conversation, 2-3 bullet points of discussion, and any follow-up action items. Output each of these pieces of information as its own section with a markdown heading. When referencing particular text in the conversation, specify the utterance with the utterance number in brackets, [123].\n",
    "    \n",
    "    {}\n",
    "\"\"\"\n",
    "gen(prompt.format(conv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
