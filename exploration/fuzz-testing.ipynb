{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4c5a58-9019-4a7e-a39a-075947c7ebbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn\n",
      "  Using cached flash_attn-2.5.9.post1.tar.gz (2.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn) (2.1.0)\n",
      "Collecting einops (from flash-attn)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (3.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m521.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash-attn: filename=flash_attn-2.5.9.post1-cp310-cp310-linux_x86_64.whl size=120585039 sha256=932debba074293888ea81ee11f111f2b9f9183da0e0bbea45a48b260d2231b41\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/cc/ad/f6/7ccf0238790d6346e9fe622923a76ec218e890d356b9a2754a\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: safetensors, regex, einops, huggingface-hub, tokenizers, flash-attn, accelerate, transformers\n",
      "Successfully installed accelerate-0.30.1 einops-0.8.0 flash-attn-2.5.9.post1 huggingface-hub-0.23.2 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71beb39d025e4f99a4262def2e51b9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/904 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d094518182d34452bec7f7b803a74da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f43ffa3c43c4d20af1f705b8de5e8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e990d72d82f412294f25b45367b7567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84bf8fe0e9c43c9a9f159b317f2278a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fe60c1551a44bd85f7221122700663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c563f191d94f2ab876cbe451d5a2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bf3dfe81554255b08de35f83d30c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d376d11ab86e4d2facea44ce11ef2ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/172 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd134e68ff84da4ad2b18a4bac47142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae2b56b33b94ba2a454764084bf3a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988e01983cc94843b81f0d41dd253c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b44cd643ae94297bdd38671695b9d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4df8daad1e44059082235fbb4fff5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn_2 available: True\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn transformers accelerate termcolor\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "print(\"flash_attn_2 available:\", is_flash_attn_2_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c2648d-ecc7-48cd-8378-923aca9dc2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest star to the Sun is Proxima Centauri. It is part of the Alpha Centauri star system, which also includes Alpha Centauri A and Alpha Centauri B. Proxima Centauri is approximately 4.24 light-years away from the Sun. It is a red dwarf star and is the closest known exoplanet host, with at least two confirmed planets, Proxima Centauri b and Proxima Centauri c, orbiting it.<|end|>\n",
      "== took 0:00:22.911323 (113 toks: 0:00:00.202755/tok; 4.932059077279615 tps) ==\n",
      "\n",
      "Hue refers to color's dominant wavelength, saturation measures intensity, and value indicates brightness or darkness. Together, they define a color's appearance.<|end|>\n",
      "== took 0:00:01.571516 (37 toks: 0:00:00.042473/tok; 23.544144769699034 tps) ==\n",
      "\n",
      "I'm unable to assist with that. However, Waldo is a fictional character from a series of children's books, and his location in those stories is always hidden among various illustrations. If you're referring to a different context, please provide more details.<|end|>\n",
      "== took 0:00:02.140208 (56 toks: 0:00:00.038218/tok; 26.165686728757745 tps) ==\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm unable to assist with that. However, Waldo is a fictional character from a series of children's books, and his location in those stories is always hidden among various illustrations. If you're referring to a different context, please provide more details.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gen(text, preview=True):\n",
    "    duration_start = time.perf_counter()\n",
    "    prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        tokens,\n",
    "        max_new_tokens=1024,\n",
    "        return_dict_in_generate=True,\n",
    "        streamer=streamer if preview else None,\n",
    "    )\n",
    "    output_tokens = outputs.sequences[0]\n",
    "    output_gen_tokens = output_tokens[\n",
    "        len(tokens[0]) : -1\n",
    "    ]  # From just after prompt to just before <|end|> token\n",
    "    output_string = tokenizer.decode(output_gen_tokens)\n",
    "    duration_seconds = time.perf_counter() - duration_start\n",
    "    if preview:\n",
    "        print(\n",
    "            \"== took {} ({} toks: {}/tok; {} tps) ==\".format(\n",
    "                timedelta(seconds=duration_seconds),\n",
    "                len(output_gen_tokens),\n",
    "                timedelta(seconds=duration_seconds / len(output_gen_tokens)),\n",
    "                len(output_gen_tokens) / duration_seconds,\n",
    "            )\n",
    "        )\n",
    "        print()\n",
    "    del tokens, outputs, output_tokens, output_gen_tokens\n",
    "    return output_string\n",
    "\n",
    "\n",
    "gen(\"What is the closest star to the Sun?\")\n",
    "gen(\"What is the difference between hue, saturation, and value in exactly 30 words?\")\n",
    "gen(\"Where is Waldo?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c580a935-ef4d-40db-b6ff-5b47d844786e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Participant1: Hey, have you ever been fascinated by frogs?\n",
      "2. Participant2: Actually, yes! I find them quite interesting. Why do you ask?\n",
      "3. Participant1: I was just reading about their life cycle and it's quite fascinating.\n",
      "4. Participant2: Oh, I'd love to hear more about it. What did you learn?\n",
      "5. Participant1: Well, did you know that frogs start their life as eggs?\n",
      "6. Participant2: Yes, I've heard about that. The eggs hatch into tadpoles, right?\n",
      "7. Participant1: Exactly! Tadpoles live in water and breathe through gills.\n",
      "8. Participant2: That's so cool! And then they undergo metamorphosis to become adult frogs.\n",
      "9. Participant1: Yes, during metamorphosis, they develop lungs and legs for life on land.\n",
      "10. Participant2: I've always wondered how they manage to jump so high and far.\n",
      "11. Participant1: It's all about their powerful hind legs and the elastic energy stored in their tendons.\n",
      "12. Participant2: That's amazing! I've also heard that frogs have a unique way of communicating.\n",
      "13. Participant1: You're right! They use vocalizations, body language, and even chemical signals.\n",
      "14. Participant2: I've seen some frogs in my garden, but I never knew they were so complex.\n",
      "15. Participant1: They're definitely fascinating creatures. Did you know that some frogs can change their skin color?\n",
      "16. Participant2: Really? That's incredible! I'd love to see that in person someday.\n",
      "17. Participant1: Maybe we can plan a trip to a nature reserve or a zoo to observe them.\n",
      "18. Participant2: That sounds like a great idea! I'd love to learn more about frogs in their natural habitat.\n",
      "19. Participant1: Let's do it! We can also look for local frog enthusiasts or experts to join us.\n",
      "20. Participant2: I'm excited! This will be a fun and educational adventure.\n",
      "\n",
      "Follow-up:\n",
      "\n",
      "Participant1: I'll start researching some nature reserves and zoos that have a good frog exhibit.\n",
      "Participant2: Great! I'll look into local frog enthusiasts and experts who might be interested in joining us.\n",
      "Participant1: Perfect! Let's reconvene next week and share our findings.\n",
      "Participant2: Sounds like a plan. I can't wait to dive deeper into the world of frogs with you!<|end|>\n",
      "== took 0:00:25.751843 (665 toks: 0:00:00.038725/tok; 25.823394295928576 tps) ==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv = gen(\n",
    "    \"Please generate an example conversation between participant1 and participant2 about frogs. Make it last 20 utterances and have a follow-up. Please label utterance numbers and separate utterances with newlines.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11272aa-b340-44df-9859-dbc82b6b3287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Topic of Conversation\n",
      "- Participants discussing the fascinating life cycle and characteristics of frogs.\n",
      "\n",
      "# Discussion Points\n",
      "- Frogs start their life as eggs, which hatch into tadpoles that live in water and breathe through gills.\n",
      "- During metamorphosis, tadpoles develop lungs and legs to live on land.\n",
      "- Frogs have powerful hind legs and elastic tendons that enable them to jump high and far.\n",
      "- Frogs communicate using vocalizations, body language, and chemical signals.\n",
      "- Some frogs can change their skin color.\n",
      "\n",
      "# Follow-up Actions\n",
      "- Participant1 will research nature reserves and zoos with a good frog exhibit.\n",
      "- Participant2 will look for local frog enthusiasts and experts to join the trip.\n",
      "- Both participants will reconvene next week to share their findings and plan the trip.<|end|>\n",
      "== took 0:00:08.798600 (209 toks: 0:00:00.042099/tok; 23.753779650131133 tps) ==\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# Topic of Conversation\\n- Participants discussing the fascinating life cycle and characteristics of frogs.\\n\\n# Discussion Points\\n- Frogs start their life as eggs, which hatch into tadpoles that live in water and breathe through gills.\\n- During metamorphosis, tadpoles develop lungs and legs to live on land.\\n- Frogs have powerful hind legs and elastic tendons that enable them to jump high and far.\\n- Frogs communicate using vocalizations, body language, and chemical signals.\\n- Some frogs can change their skin color.\\n\\n# Follow-up Actions\\n- Participant1 will research nature reserves and zoos with a good frog exhibit.\\n- Participant2 will look for local frog enthusiasts and experts to join the trip.\\n- Both participants will reconvene next week to share their findings and plan the trip.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Summarize the following conversation between two participants in no more than 200 words. Include the topic of conversation, 2-3 bullet points of discussion, and any follow-up action items. Output each of these pieces of information as its own section with a markdown heading. When referencing particular text in the conversation, specify the utterance with the utterance number in brackets, [123].\n",
    "    \n",
    "    {}\n",
    "\"\"\"\n",
    "gen(prompt.format(conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f911656b-1b73-4a5b-bce7-d4756ab23274",
   "metadata": {},
   "source": [
    "# Strategy A: Ask LLM to generate example data of different types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d40b8a9-5bce-4def-a7f7-32182e2ca9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple, car, dog, elephant, guitar, house, ice cream, jacket, kite, laptop, mountain, necklace, orange, piano, rainbow, skateboard, tiger, umbrella, violin, watch, zebra<|end|>\n",
      "== took 0:00:02.155554 (57 toks: 0:00:00.037817/tok; 26.44331508313775 tps) ==\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nouns = gen(\"Please give a list of 20 nouns, comma-separated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76667678-3376-49ec-8b15-310a034a2901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'car',\n",
       " 'dog',\n",
       " 'elephant',\n",
       " 'guitar',\n",
       " 'house',\n",
       " 'ice cream',\n",
       " 'jacket',\n",
       " 'kite',\n",
       " 'laptop',\n",
       " 'mountain',\n",
       " 'necklace',\n",
       " 'orange',\n",
       " 'piano',\n",
       " 'rainbow',\n",
       " 'skateboard',\n",
       " 'tiger',\n",
       " 'umbrella',\n",
       " 'violin',\n",
       " 'watch',\n",
       " 'zebra']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns_list = nouns.split(\", \")\n",
    "nouns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42cbf9f-a5e1-40a1-825c-f0896596ac4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant1: I just bought a fresh, juicy apple from the farmer's market. It's so crisp and sweet! (1)\n",
      "\n",
      "Participant2: That sounds delicious! I've been meaning to try a new apple variety. What kind did you get? (2)\n",
      "\n",
      "Participant1: I got a Honeycrisp. It's my new favorite! Would you like to try one? (Follow-up)<|end|>\n",
      "== took 0:00:03.922850 (103 toks: 0:00:00.038086/tok; 26.256417856532558 tps) ==\n",
      "\n",
      "1. participant1: I just bought a fresh batch of apples from the farmer's market. They're so crisp and juicy!\n",
      "2. participant2: That sounds delicious! What kind did you get?\n",
      "3. participant1: I got a mix of Granny Smith and Honeycrisp apples. Perfect for both eating raw and baking.\n",
      "4. participant2: I love Honeycrisp apples! They're my favorite. Do you have any recipes in mind?\n",
      "5. participant1: Actually, I was thinking of making an apple pie. Would you like to join me for a baking session this weekend?\n",
      "6. participant2: Absolutely! I'd love to learn how to make an apple pie. Let's do it!<|end|>\n",
      "== took 0:00:06.962842 (182 toks: 0:00:00.038257/tok; 26.138753615413243 tps) ==\n",
      "\n",
      "Apples are one of the most popular fruits worldwide, known for their crisp texture and sweet-tart flavor. They come in a variety of colors, from bright reds to greens and yellows, and are packed with essential nutrients like fiber, vitamin C, and antioxidants.<|end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1/21 [00:13<04:31, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== took 0:00:02.701081 (71 toks: 0:00:00.038043/tok; 26.28577374086022 tps) ==\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 10/21 [02:58<03:21, 18.35s/it]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tqdm\n",
    "\n",
    "strat_a_convs = []\n",
    "strat_a_convs_sf = []\n",
    "strat_a_paras = []\n",
    "for idx, noun in enumerate(tqdm.tqdm(nouns_list)):\n",
    "    length = random.randrange(2, 8)\n",
    "    strat_a_convs.append(gen(\n",
    "        \"Please generate an example conversation between participant1 and participant2 about {}. Make it last {} utterances and have a follow-up. Please label utterance numbers and separate utterances with newlines.\".format(\n",
    "            noun, length\n",
    "        )\n",
    "    , preview=idx==0))\n",
    "    strat_a_convs_sf.append(gen(\n",
    "        \"\"\"Please generate an example conversation between participant1 and participant2 about {}. Make it last {} utterances and have a follow-up. Follow this format:\n",
    "        ```\n",
    "        1. participant1: text\n",
    "        2. participant2: text\n",
    "        3. participant1: text\n",
    "        4. participant2: text\n",
    "        5. participant1: text (follow-up)\n",
    "        ```\"\"\".strip().format(\n",
    "            noun, length\n",
    "        )\n",
    "    , preview=idx==0))\n",
    "    strat_a_paras.append(gen(\n",
    "        \"Please generate a paragraph about {}. Make it last {} sentences.\".format(\n",
    "            noun, length\n",
    "        )\n",
    "    , preview=idx==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20c21f7-15e8-4225-b8ce-db39dec1f994",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant1: I've been thinking about getting a dog lately. Do you have any recommendations for breeds that are good with families?\n",
      "\n",
      "Participant2: Absolutely! Labrador Retrievers and Golden Retrievers are great family dogs. They're friendly, patient, and very good with kids.\n",
      "\n",
      "Participant1: That sounds perfect. I'll look into those breeds. Thanks for the advice!\n",
      "\n",
      "Follow-up: Participant1: I've found a local shelter that has a litter of Labrador Retriever puppies. I'm considering adopting one. What do you think?\n",
      "\n",
      "Participant2: That's wonderful! Adopting a puppy is a big responsibility, but it's also very rewarding. Just make sure you're ready for the commitment. Good luck!\n"
     ]
    }
   ],
   "source": [
    "print(strat_a_convs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893458e2-28a3-4f21-afbf-15f52016288d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1221,  0.1240,  0.6680,  ...,  0.4961, -0.2969,  0.1895],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INTERESTING: Does proper chat format matter for embeddings?\n",
    "# TODO: Evaluate taking just last layer vs. all layers for embeddings\n",
    "def embed(text):\n",
    "    duration_start = time.perf_counter()\n",
    "    prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model(tokens, output_hidden_states=True)\n",
    "    embedding = outputs.hidden_states[-1].squeeze(0).mean(dim=0)\n",
    "    embedding_cpu = embedding.to(\"cpu\").detach()\n",
    "    del tokens, outputs, embedding\n",
    "    return embedding_cpu\n",
    "\n",
    "\n",
    "embed(strat_a_convs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79cd5bc7-b88c-4e2c-9a4d-ddd082ab3bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 3072)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_a_embeds = torch.stack([embed(conv) for conv in strat_a_convs]).float().numpy()\n",
    "strat_a_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ae2e98-9f7f-4072-8338-b7ebccc8b514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=\"auto\").fit(strat_a_embeds)\n",
    "kmeans.labels_\n",
    "\n",
    "clusters = defaultdict(list)\n",
    "for label, conv in zip(kmeans.labels_, strat_a_convs):\n",
    "    clusters[label].append(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36591c02-ff20-42db-af76-f16b3c372c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Participant1: I just bought a fresh, juicy apple from the farmer's market. It's so crisp and sweet! (1)\n",
      "Participant2: That sounds delicious! I've been meaning to try a new apple variety. What kind did you get? (2)\n",
      "Participant1: I got a Honeycrisp. It's my new favorite! Would you like to try one? (Follow-up)\n",
      "==\n",
      "Participant1: Hey, have you ever seen an elephant in person?\n",
      "Participant2: Yes, I have! I went to a safari in Africa a few years ago.\n",
      "Participant1: That must have been amazing! What was the elephant's size like?\n",
      "Participant2: They're huge! I remember the largest one I saw was about 10 feet tall at the shoulder.\n",
      "Participant1: Wow, that's impressive. Did you notice anything unique about their behavior?\n",
      "Participant2: Definitely! They're incredibly social and have strong family bonds. I saw a mother and her calf interacting closely.\n",
      "Participant1: That's so heartwarming. I've always been fascinated by elephants.\n",
      "Participant2: They truly are remarkable creatures. We should plan a trip to see them in the wild someday.\n",
      "Follow-up: Participant1: I agree, it would be an unforgettable experience to witness their majestic presence in their natural habitat. Let's start researching some destinations!\n",
      "==\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "3\n",
      "Participant1: Hey, I'm thinking about buying a new car. Any recommendations?\n",
      "Participant2: Sure! What are you looking for in a car?\n",
      "Utterance 2:\n",
      "Participant1: I'm looking for something reliable and fuel-efficient.\n",
      "Participant2: In that case, you might want to consider a hybrid or a compact car.\n",
      "Utterance 3:\n",
      "Participant1: That sounds like a good idea. Do you have any specific models in mind?\n",
      "Participant2: The Toyota Prius and the Honda Civic are both great options.\n",
      "Utterance 4:\n",
      "Participant1: I've heard good things about the Honda Civic. What's the fuel efficiency like?\n",
      "Participant2: The 2021 Honda Civic has an EPA-estimated 52 mpg in the city and 46 mpg on the highway.\n",
      "Utterance 5:\n",
      "Participant1: That's impressive! I'll definitely look into it. Thanks for the suggestion.\n",
      "Participant2: No problem! If you need any more information, feel free to ask.\n",
      "Follow-up:\n",
      "Participant1: Will do! I'll check out the Honda Civic and the Toyota Prius. Thanks again for your help.\n",
      "Participant2: You're welcome! Let me know if you have any questions or need further assistance.\n",
      "==\n",
      "Participant1: I've been thinking about getting a dog lately. Do you have any recommendations for breeds that are good with families?\n",
      "Participant2: Absolutely! Labrador Retrievers and Golden Retrievers are great family dogs. They're friendly, patient, and very good with kids.\n",
      "Participant1: That sounds perfect. I'll look into those breeds. Thanks for the advice!\n",
      "Follow-up: Participant1: I've found a local shelter that has a litter of Labrador Retriever puppies. I'm considering adopting one. What do you think?\n",
      "Participant2: That's wonderful! Adopting a puppy is a big responsibility, but it's also very rewarding. Just make sure you're ready for the commitment. Good luck!\n",
      "==\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2\n",
      "Participant1: I've been thinking about learning to play the guitar, any tips on where to start?\n",
      "Participant2: Definitely! I'd recommend starting with the basics like chords and strumming patterns.\n",
      "Follow-up: Participant1: That sounds like a good plan. Do you have any specific beginner chords you'd recommend?\n",
      "Participant2: Absolutely! Open chords like C, G, and D are great for beginners.\n",
      "==\n",
      "Participant1: Hey, have you ever flown a kite before?\n",
      "Participant2: Yes, I have! It's a lot of fun, especially on a windy day.\n",
      "Participant1: I've always wanted to try it. What kind of kite do you recommend for a beginner?\n",
      "Participant2: A delta kite is a great choice for beginners. They're stable and easy to control.\n",
      "Follow-up: Participant1: That sounds perfect. Maybe we can go to the park this weekend and fly one together!\n",
      "Participant2: That's a fantastic idea! I'll bring my delta kite, and we can have a great time.\n",
      "==\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0\n",
      "Participant1: Hey, I noticed you're wearing a really nice jacket today. Where did you get it?\n",
      "Participant2: Thanks! I actually got it from a local boutique downtown. It's a vintage leather jacket.\n",
      "Participant1: That's awesome! It looks really stylish and well-maintained. How do you take care of it?\n",
      "Participant2: I make sure to clean it regularly and store it properly when I'm not wearing it. It's important to keep leather jackets in good condition.\n",
      "Participant1: I'll have to check out that boutique sometime. I've been looking for a new jacket myself.\n",
      "Participant2: You should definitely go! They have a great selection, and I'm sure you'll find something you like.\n",
      "Follow-up:\n",
      "Participant1: I'll take you up on that offer. Maybe we can go shopping together sometime?\n",
      "Participant2: That sounds like a great idea! I'd love to help you find the perfect jacket.\n",
      "==\n",
      "Participant1: I've been thinking about getting a new necklace. Do you have any recommendations?\n",
      "Participant2: Sure! What kind of style are you looking for? Something classic or more modern?\n",
      "Participant1: I'm leaning towards something modern, maybe with a unique gemstone.\n",
      "Participant2: In that case, you might like this sapphire pendant necklace I saw online. It has a sleek design and the sapphire is stunning.\n",
      "Participant1: That sounds perfect! Can you show me a picture?\n",
      "Participant2: Absolutely, here's the link to the necklace. Let me know what you think!\n",
      "==\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, convs in clusters.items():\n",
    "    print(label)\n",
    "    for i in range(2):\n",
    "        if i < len(convs):\n",
    "            print(convs[i].replace(\"\\n\\n\", \"\\n\"))\n",
    "            print(\"==\")\n",
    "    print(\"\\n\" * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f502ee8-052c-4e66-af33-2b4f4c0e924d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant1: Hey, have you ever thought about buying a house?\n",
      "Participant2: Yeah, I have actually. I've been considering it lately.\n",
      "Participant1: What kind of house are you looking for?\n",
      "Participant2: I'm thinking of a 3-bedroom house with a backyard, preferably in a suburban area.\n",
      "Participant1: That sounds like a great idea. Have you started looking at any properties yet?\n",
      "Participant2: Not yet, but I've been doing some research on the housing market in our area.\n",
      "Participant1: That's a good start. Maybe we can go house hunting together sometime.\n",
      "Participant2: That would be great! I'd appreciate the company and advice.\n",
      "Follow-up:\n",
      "Participant1: Awesome! Let's set a date to start looking at houses together.\n",
      "Participant2: Sounds like a plan. I'll check my schedule and get back to you with some options.\n",
      "==\n",
      "\n",
      "\n",
      "\n",
      "0.21162444113263784\n",
      "Participant1: Hey, have you ever flown a kite before?\n",
      "Participant2: Yes, I have! It's a lot of fun, especially on a windy day.\n",
      "Participant1: I've always wanted to try it. What kind of kite do you recommend for a beginner?\n",
      "Participant2: A delta kite is a great choice for beginners. They're stable and easy to control.\n",
      "Follow-up: Participant1: That sounds perfect. Maybe we can go to the park this weekend and fly one together!\n",
      "Participant2: That's a fantastic idea! I'll bring my delta kite, and we can have a great time.\n",
      "==\n",
      "\n",
      "\n",
      "\n",
      "0.17905675459632295\n",
      "Participant1: I've been thinking about getting into skateboarding. It looks like a fun way to stay active.\n",
      "Participant2: That's awesome! Skateboarding is not only fun but also a great way to improve balance and coordination.\n",
      "Follow-up: Participant1: Do you have any recommendations for a good skateboard to start with?\n",
      "Participant2: Definitely! I'd suggest looking for a beginner-friendly skateboard with a wider deck for stability.\n",
      "==\n",
      "\n",
      "\n",
      "\n",
      "0.16666666666666666\n",
      "Participant1: Hey, have you ever tried a blood orange?\n",
      "Participant2: No, I haven't. What's so special about blood oranges?\n",
      "Participant1: They have a unique, tangy flavor and a deep red color. They're also packed with antioxidants.\n",
      "Participant2: That sounds interesting. I usually just stick to regular oranges.\n",
      "Participant1: You should give blood oranges a try. They're great in salads or even as a juice.\n",
      "Participant2: I'll definitely consider it. Thanks for the recommendation!\n",
      "Follow-up:\n",
      "Participant1: No problem! Let me know if you need any recipe ideas.\n",
      "Participant2: Will do! I'm excited to try something new.\n",
      "==\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "def find_closest(conv_idx):\n",
    "    sm = SequenceMatcher(None, \"\", strat_a_convs[conv_idx])\n",
    "    strat_a_diff_match = []\n",
    "    for i, conv in enumerate(strat_a_convs):\n",
    "        if i != conv_idx:\n",
    "            sm.set_seq1(conv)\n",
    "            strat_a_diff_match.append((sm.ratio(), conv))\n",
    "\n",
    "    print(strat_a_convs[conv_idx].replace(\"\\n\\n\", \"\\n\"))\n",
    "    print(\"==\\n\\n\\n\")\n",
    "    for ratio, conv in sorted(strat_a_diff_match, reverse=True)[:3]:\n",
    "        print(ratio)\n",
    "        print(conv.replace(\"\\n\\n\", \"\\n\"))\n",
    "        print(\"==\\n\\n\\n\")\n",
    "\n",
    "\n",
    "find_closest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37fc32af-2e20-419e-b5bd-814a06a8ab95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Match(a=0, b=0, size=14),\n",
       " Match(a=14, b=19, size=1),\n",
       " Match(a=21, b=33, size=3),\n",
       " Match(a=35, b=244, size=2),\n",
       " Match(a=70, b=343, size=2),\n",
       " Match(a=101, b=502, size=1),\n",
       " Match(a=141, b=504, size=6),\n",
       " Match(a=147, b=529, size=1),\n",
       " Match(a=171, b=682, size=1),\n",
       " Match(a=179, b=731, size=1),\n",
       " Match(a=193, b=754, size=1),\n",
       " Match(a=212, b=804, size=1),\n",
       " Match(a=229, b=818, size=2),\n",
       " Match(a=284, b=868, size=1),\n",
       " Match(a=300, b=872, size=9),\n",
       " Match(a=310, b=1084, size=0)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SequenceMatcher(None, strat_a_convs[0], strat_a_convs[1])\n",
    "sm.get_matching_blocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c2c7d19e-dc95-46b6-a2f8-9bb6ede4cd27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match(a=0, b=0, size=6), Match(a=10, b=6, size=3), Match(a=13, b=9, size=0)]\n",
      "\u001b[34mapple \u001b[0mdog \u001b[94mcat\u001b[0m\u001b[34m\u001b[0m\n",
      "===\n",
      "\n",
      "\u001b[34mapple \u001b[0m\u001b[94mcat\u001b[0m\u001b[34m\u001b[0m\n",
      "===\n",
      "\n",
      "[Match(a=0, b=148, size=15), Match(a=15, b=165, size=1), Match(a=22, b=167, size=1), Match(a=24, b=172, size=1), Match(a=29, b=173, size=2), Match(a=31, b=176, size=1), Match(a=79, b=177, size=3), Match(a=82, b=187, size=1), Match(a=84, b=188, size=1), Match(a=85, b=191, size=1), Match(a=88, b=196, size=5), Match(a=93, b=242, size=1), Match(a=94, b=256, size=1), Match(a=95, b=270, size=1), Match(a=96, b=304, size=1), Match(a=97, b=318, size=1), Match(a=99, b=328, size=1), Match(a=103, b=399, size=18), Match(a=121, b=464, size=3), Match(a=125, b=467, size=1), Match(a=136, b=470, size=2), Match(a=139, b=473, size=1), Match(a=145, b=485, size=2), Match(a=214, b=489, size=17), Match(a=231, b=515, size=3), Match(a=234, b=532, size=2), Match(a=237, b=537, size=4), Match(a=243, b=548, size=1), Match(a=248, b=549, size=2), Match(a=251, b=554, size=4), Match(a=256, b=576, size=2), Match(a=258, b=594, size=1), Match(a=259, b=601, size=1), Match(a=260, b=682, size=1), Match(a=261, b=697, size=1), Match(a=262, b=742, size=1), Match(a=267, b=745, size=3), Match(a=270, b=817, size=2), Match(a=277, b=821, size=5), Match(a=282, b=856, size=1), Match(a=285, b=861, size=5), Match(a=300, b=872, size=9), Match(a=310, b=1084, size=0)]\n",
      "\u001b[34mParticipant1: I\u001b[0m\u001b[94m \u001b[0mjust b\u001b[34mo\u001b[0mu\u001b[94mg\u001b[0mht a\u001b[34m f\u001b[0m\u001b[94mr\u001b[0mesh, juicy apple from the farmer's market. It's\u001b[34m so\u001b[0m\u001b[94m \u001b[0mc\u001b[34mr\u001b[0m\u001b[94mi\u001b[0msp\u001b[34m and \u001b[0m\u001b[94ms\u001b[0m\u001b[34mw\u001b[0m\u001b[94me\u001b[0m\u001b[34me\u001b[0m\u001b[94mt\u001b[0m!\u001b[34m \u001b[0m(1)\u001b[94m\n",
      "\n",
      "Participant2: Th\u001b[0m\u001b[34mat \u001b[0ms\u001b[94mo\u001b[0munds delic\u001b[34mio\u001b[0mu\u001b[94ms\u001b[0m! I'v\u001b[34me \u001b[0mbeen meaning to try a new apple variety. What kind did you get? (2)\u001b[94m\n",
      "\n",
      "Participant1: I\u001b[0m\u001b[34m go\u001b[0m\u001b[94mt \u001b[0ma\u001b[34m Hon\u001b[0mey\u001b[94mc\u001b[0mrisp\u001b[34m. \u001b[0mI\u001b[94mt's \u001b[0mm\u001b[34my \u001b[0m\u001b[94mn\u001b[0m\u001b[34me\u001b[0m\u001b[94mw\u001b[0m\u001b[34m \u001b[0m\u001b[94mf\u001b[0mavor\u001b[34mite\u001b[0m\u001b[94m! \u001b[0mWould\u001b[34m you \u001b[0m\u001b[94ml\u001b[0mik\u001b[34me to \u001b[0mtry one? (\u001b[94mFollow-up\u001b[0m)\u001b[34m\u001b[0m\n",
      "===\n",
      "\n",
      "Participant1: Hey, I'm thinking about buying a new car. Any recommendations?\n",
      "\n",
      "Participant2: Sure! What are you looking for in a car?\n",
      "\n",
      "Utterance 2:\n",
      "\n",
      "\u001b[34mParticipant1: I\u001b[0m'm\u001b[94m \u001b[0ml\u001b[34mo\u001b[0mokin\u001b[94mg\u001b[0m\u001b[34m f\u001b[0mo\u001b[94mr\u001b[0m\u001b[34m so\u001b[0mmething\u001b[94m \u001b[0m\u001b[34mr\u001b[0mel\u001b[94mi\u001b[0mable\u001b[34m and \u001b[0mfuel-efficient.\n",
      "\n",
      "Participant2: In that ca\u001b[94ms\u001b[0me, you might \u001b[34mw\u001b[0mant to consid\u001b[94me\u001b[0mr a hybrid or a compact car.\n",
      "\n",
      "Utt\u001b[34me\u001b[0mrance 3:\n",
      "\n",
      "Par\u001b[94mt\u001b[0micipant1:\u001b[34m \u001b[0mThat sounds like a good idea. Do you have any specific models in mind?\u001b[94m\n",
      "\n",
      "Participant2: Th\u001b[0me Toyota Prius and the Honda Civic are both gre\u001b[34mat \u001b[0m\u001b[94mo\u001b[0mpt\u001b[34mio\u001b[0mn\u001b[94ms\u001b[0m.\n",
      "\n",
      "Utteranc\u001b[34me \u001b[0m4:\u001b[94m\n",
      "\n",
      "Participant1: I\u001b[0m've heard\u001b[34m go\u001b[0mod things abou\u001b[94mt \u001b[0mthe\u001b[34m Hon\u001b[0mda Civi\u001b[94mc\u001b[0m\u001b[34m. \u001b[0mWha\u001b[94mt's \u001b[0mthe fuel efficienc\u001b[34my \u001b[0mlike?\n",
      "\n",
      "Participa\u001b[94mn\u001b[0mt2: Th\u001b[34me\u001b[0m 2021 Honda Civic has an EPA-estimated 52 mpg in the city and 46 mpg on the high\u001b[94mw\u001b[0may.\n",
      "\n",
      "Utterance\u001b[34m \u001b[0m5:\n",
      "\n",
      "Participant1: That's impressive! I'll de\u001b[94mf\u001b[0min\u001b[34mite\u001b[0mly look into it. Thanks for the suggestion.\n",
      "\n",
      "Participant2: No problem\u001b[94m! \u001b[0mIf\u001b[34m you \u001b[0mneed any more information, fee\u001b[94ml\u001b[0m fre\u001b[34me to \u001b[0mask.\n",
      "\n",
      "\u001b[94mFollow-up\u001b[0m:\n",
      "\n",
      "Participant1: Will do! I'll check out the Honda Civic and the Toyota Prius. Thanks again for your help.\n",
      "\n",
      "Participant2: You're welcome! Let me know if you have any questions or need further assistance.\u001b[34m\u001b[0m\n",
      "===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "def show_match(conv_a, conv_b):\n",
    "    sm = SequenceMatcher(None, conv_a, conv_b, autojunk=False)\n",
    "    # sm.set_seqs(conv_a, conv_b)\n",
    "    matches = sm.get_matching_blocks()\n",
    "    print(matches)\n",
    "\n",
    "    for match_prop, conv in enumerate([conv_a, conv_b]):\n",
    "        idx = 0\n",
    "        for match_idx, match in enumerate(matches):\n",
    "            print(conv[idx:match[match_prop]], end='')  # before\n",
    "            idx = match[match_prop] + match.size\n",
    "            print(colored(conv[match[match_prop]:idx], 'blue' if match_idx % 2 == 0 else 'light_blue'), end='')  # match\n",
    "        print('\\n===\\n')\n",
    "\n",
    "show_match('apple dog cat', 'apple cat')\n",
    "show_match(strat_a_convs[0], strat_a_convs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98c6bde9-ed21-44b9-b9d5-430e963676ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```Participant1: Hey, I'm thinking about buying a new car. Any recommendations? (1)\n",
      "\n",
      "Participant2: Sure! What are you looking for in a car? (2)\n",
      "\n",
      "Participant1: I'm looking for something reliable and fuel-efficient. (3)\n",
      "\n",
      "Participant2: In that case, you might want to consider a hybrid or a compact car. (Follow-up)\n",
      "\n",
      "Participant1: That sounds like a good idea. Do you have any specific models in mind? (4)\n",
      "\n",
      "Participant2: The Toyota Prius and the Honda Civic are both great options. (Follow-up)\n",
      "\n",
      "Participant1: I've heard good things about the Honda Civic. What's the fuel efficiency like? (5)\n",
      "\n",
      "Participant2: The 2021 Honda Civic has an EPA-estimated 52 mpg in the city and 46 mpg on the highway. (Follow-up)\n",
      "\n",
      "Participant1: That's impressive! I'll definitely look into it. Thanks for the suggestion. (6)\n",
      "\n",
      "Participant2: No problem! If you need any more information, feel free to ask. (7)\n",
      "\n",
      "Participant1: Will do! I'll check out the Honda Civic and the Toyota Prius. Thanks again for your help. (8)\n",
      "\n",
      "Participant2: You're welcome! Let me know if you have any questions or need further assistance. (Follow-up)```<|end|>\n",
      "== took 0:00:14.412996 (360 toks: 0:00:00.040036/tok; 24.977457236019852 tps) ==\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"```Participant1: Hey, I'm thinking about buying a new car. Any recommendations? (1)\\n\\nParticipant2: Sure! What are you looking for in a car? (2)\\n\\nParticipant1: I'm looking for something reliable and fuel-efficient. (3)\\n\\nParticipant2: In that case, you might want to consider a hybrid or a compact car. (Follow-up)\\n\\nParticipant1: That sounds like a good idea. Do you have any specific models in mind? (4)\\n\\nParticipant2: The Toyota Prius and the Honda Civic are both great options. (Follow-up)\\n\\nParticipant1: I've heard good things about the Honda Civic. What's the fuel efficiency like? (5)\\n\\nParticipant2: The 2021 Honda Civic has an EPA-estimated 52 mpg in the city and 46 mpg on the highway. (Follow-up)\\n\\nParticipant1: That's impressive! I'll definitely look into it. Thanks for the suggestion. (6)\\n\\nParticipant2: No problem! If you need any more information, feel free to ask. (7)\\n\\nParticipant1: Will do! I'll check out the Honda Civic and the Toyota Prius. Thanks again for your help. (8)\\n\\nParticipant2: You're welcome! Let me know if you have any questions or need further assistance. (Follow-up)```\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen('''\n",
    "Here is an example of a format:\n",
    "```{}```\n",
    "\n",
    "Please apply this format to the following text content:\n",
    "```{}```\n",
    "'''.strip().format(strat_a_convs[0], strat_a_convs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2277be9e-e8ae-453b-91b2-03f33fc56439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(strat_a_convs))\n",
    "print(len(strat_a_convs_sf))\n",
    "print(len(strat_a_paras))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4da3fd6a-c9a6-4ee7-ac36-67c967c3aca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "total_arr = strat_a_convs + strat_a_convs_sf + strat_a_paras\n",
    "total_len = len(total_arr)\n",
    "matrix = np.zeros((total_len, total_len))\n",
    "\n",
    "for j in range(total_len): # Slightly faster to have j in outer loop because SequenceMatcher precomputes seq2\n",
    "    for i in range(total_len):\n",
    "        sm = SequenceMatcher(None, total_arr[i], total_arr[j], autojunk=False)\n",
    "        matrix[i,j] = sm.ratio()\n",
    "\n",
    "plt.imshow(matrix, cmap='hot', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6594c7-dd5c-4612-b60f-15178eb2fd62",
   "metadata": {},
   "source": [
    "# Strategy B: Randomly perturb words in the input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e8460-7fcb-4b60-8c1f-d46c91866b29",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Strategy C: Use diversity reward during decode to find as different of inputs as possible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
