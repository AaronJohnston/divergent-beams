{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d67b835-1407-44e8-8e3c-b175997af185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flash-attn in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.5.9.post1)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.30.1)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: altair in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (5.3.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn) (2.1.0)\n",
      "Requirement already satisfied: einops in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from flash-attn) (0.8.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from altair) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from altair) (4.21.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from altair) (1.5.3)\n",
      "Requirement already satisfied: toolz in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from altair) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from altair) (4.10.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=3.0->altair) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=3.0->altair) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=3.0->altair) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonschema>=3.0->altair) (0.18.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=0.25->altair) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=0.25->altair) (2024.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->flash-attn) (3.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->altair) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=0.25->altair) (1.16.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbadc0ab71a4c04895b296038f31765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flash_attn_2 available: True\n"
     ]
    }
   ],
   "source": [
    "!pip install flash-attn transformers accelerate termcolor altair\n",
    "\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "from transformers.utils import is_flash_attn_2_available\n",
    "\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "print(\"flash_attn_2 available:\", is_flash_attn_2_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9650ff99-4643-4fef-8a1d-6b4413d66078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen(text, preview=True):\n",
    "    duration_start = time.perf_counter()\n",
    "    prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        tokens,\n",
    "        max_new_tokens=1024,\n",
    "        return_dict_in_generate=True,\n",
    "        streamer=streamer if preview else None,\n",
    "    )\n",
    "    output_tokens = outputs.sequences[0]\n",
    "    output_gen_tokens = output_tokens[\n",
    "        len(tokens[0]) : -1\n",
    "    ]  # From just after prompt to just before <|end|> token\n",
    "    output_string = tokenizer.decode(output_gen_tokens)\n",
    "    duration_seconds = time.perf_counter() - duration_start\n",
    "    if preview:\n",
    "        print(\n",
    "            \"== took {} ({} toks: {}/tok; {} tps) ==\".format(\n",
    "                timedelta(seconds=duration_seconds),\n",
    "                len(output_gen_tokens),\n",
    "                timedelta(seconds=duration_seconds / len(output_gen_tokens)),\n",
    "                len(output_gen_tokens) / duration_seconds,\n",
    "            )\n",
    "        )\n",
    "        print()\n",
    "    del tokens, outputs, output_tokens, output_gen_tokens\n",
    "    return output_string\n",
    "\n",
    "\n",
    "def embed(text, mean_layers=False, mean_tokens=False, prompt_prefix=\"\"):\n",
    "    duration_start = time.perf_counter()\n",
    "    if prompt_prefix:\n",
    "        prompt = \"<|user|>\\n{}\\n```\\n{}\\n``` <|end|>\\n<|assistant|>\".format(\n",
    "            prompt_prefix, text\n",
    "        )\n",
    "    else:\n",
    "        prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model(tokens, output_hidden_states=True)\n",
    "    embedding = outputs.hidden_states\n",
    "    # print(len(embedding), embedding[0].shape)\n",
    "    if mean_layers:\n",
    "        # print(torch.stack(embedding).shape)\n",
    "        embedding = torch.stack(embedding).mean(dim=0)  # Mean layers\n",
    "    else:\n",
    "        embedding = embedding[-1]  # Take last layer\n",
    "\n",
    "    if mean_tokens:\n",
    "        embedding = embedding.mean(dim=1)  # Mean tokens\n",
    "    else:\n",
    "        embedding = embedding[:, -1, :]  # Take last token\n",
    "\n",
    "    embedding = embedding[0]  # Take first and only element of batch\n",
    "\n",
    "    embedding_cpu = embedding.to(\"cpu\").detach()\n",
    "    del tokens, outputs, embedding\n",
    "    return embedding_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a92f31cb-ba71-4de3-9418-cfd4c4e5a98b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   263,  1781,  4444,   363,   263, 11942,\n",
       "          7823,   297,  1120,  1227, 29973, 29871, 32007, 32001,   319,  1781,\n",
       "          4444,   363,   263, 11942,  7823,   297,  1120,  1227,   723,   367,\n",
       "           263,  5763,   293, 14089,   411,   325,  4626,   424,  6416,   900,\n",
       "         29875,   482, 29889, 13001,   284, 14354,  1033,  3160, 29901,    13,\n",
       "            13,    13, 29896, 29889,  3579,  3388,   280,  6070,   345,  4815,\n",
       "          1068, 29901,  8360,   776,   363,   967,   380, 27389,  2479,   310,\n",
       "          2654, 29892, 24841, 29892,   322, 13328,  2910,   280, 11308, 29892,\n",
       "           445, 14089, 16688,   263, 14956,   802,  1250,  8865,   363,   263,\n",
       "          6416, 11942,  7823, 29889,   450, 14089,   756, 20947,   310,  1722,\n",
       "          8162,   363, 11942, 19254,   292, 29892,   408,  1532,   408, 22049,\n",
       "          1020,  2719,   363,   263,   454,   275,   545,   368,   380,  1245,\n",
       "         29889,    13,    13,    13, 29906, 29889,  3579, 29934,  1536,   680,\n",
       "          4815,  1068, 29901,  2973,   967,  9560,  8580,  8386,   322,   278,\n",
       "          6047,   310,  4972,   292,  4094,   297,   278,  3239, 29892,   390,\n",
       "          1536,   680,  4815,   338,  4922,   363,   263, 26681,   292,  1120,\n",
       "          1227, 11942,  7823, 29889,   450, 14089,  4049,   756, 25373, 11942,\n",
       "          7823, 10161,   411,  3856,  6609,   322,  6131, 29892,   322,   278,\n",
       "         12528,   289,   929,   911,   515,   278,  8580, 12778,   304,   278,\n",
       "         21246, 25005, 29889,    13,    13,    13, 29941, 29889,  3579, 23369,\n",
       "          1705, 26035,   936, 15971,   575,  1068, 29901,   960,   366, 29915,\n",
       "           276,  3063,   363,   263,   901, 22024,   339,   309,  4444, 29892,\n",
       "           278,  8068, 26035,   936, 15971,   575,   338,   263,  2107,  7348,\n",
       "         29889,   450, 17161,   575,   526, 10423,   411,   263, 12875,   310,\n",
       "          1120,  1227, 29899, 14073, 28826, 18281,   322, 18577, 29892, 13138,\n",
       "           263,  2927,  1319,   322,  5227,   629,   424, 11942,  7823,  7271,\n",
       "         29889,    13,    13,    13,  7301,  1096,   304,  1423,   278, 14826,\n",
       "         29821,   579,  1434, 28435,   714, 29892,   322,  6963,  3412,   263,\n",
       "          1302,  1537,  9654,   300, 29892, 14294,  1067,  6046, 29892,   322,\n",
       "           263, 14563,   359,   310,  7375,   367,   369,  1179,   304,  7952,\n",
       "         25561, 10106,   596, 11942,  7823, 29889, 32000]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "def gen_diverse(text, preview=True):\n",
    "    duration_start = time.perf_counter()\n",
    "    prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "    tokens = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        tokens,\n",
    "        max_new_tokens=1024,\n",
    "        return_dict_in_generate=True,\n",
    "        streamer=streamer if preview else None,\n",
    "        num_beams=5,\n",
    "        num_beam_groups=5,\n",
    "        diversity_penalty=1.0,\n",
    "    )\n",
    "    display(outputs.sequences)\n",
    "    print(len(outputs.sequences))\n",
    "    # output_tokens = outputs.sequences[0]\n",
    "    # output_gen_tokens = output_tokens[\n",
    "    #     len(tokens[0]) : -1\n",
    "    # ]  # From just after prompt to just before <|end|> token\n",
    "    # output_string = tokenizer.decode(output_gen_tokens)\n",
    "    # duration_seconds = time.perf_counter() - duration_start\n",
    "    # if preview:\n",
    "    #     print(\n",
    "    #         \"== took {} ({} toks: {}/tok; {} tps) ==\".format(\n",
    "    #             timedelta(seconds=duration_seconds),\n",
    "    #             len(output_gen_tokens),\n",
    "    #             timedelta(seconds=duration_seconds / len(output_gen_tokens)),\n",
    "    #             len(output_gen_tokens) / duration_seconds,\n",
    "    #         )\n",
    "    #     )\n",
    "    #     print()\n",
    "    # del tokens, outputs, output_tokens, output_gen_tokens\n",
    "    # return output_string\n",
    "\n",
    "\n",
    "gen_diverse(\"What is a good setting for a picnic in autumn?\", preview=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
