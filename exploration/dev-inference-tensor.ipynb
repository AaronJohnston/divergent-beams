{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20264819-2d9c-40f4-9fcc-a2b7b019321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.31.0)\n",
      "Requirement already satisfied: optimum in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.20.0)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (12.535.133)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: coloredlogs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (2.19.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (4.25.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate optimum nvidia-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d0609e-c769-43dc-926b-f5b41beda157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdc3a9321f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import is_flash_attn_2_available\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9112e61-a3e7-4ea5-853e-f27145f37e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pynvml import *\n",
    "\n",
    "def check_gpu(step):\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"{step}: GPU memory used: {info.used // 1024**2} MB.\")\n",
    "    \n",
    "def D(obj, label=None, c=True):\n",
    "    print()\n",
    "    if label:\n",
    "        print(label)\n",
    "        \n",
    "    if isinstance(obj, tuple):\n",
    "        print(len(obj))\n",
    "    elif isinstance(obj, torch.Tensor) or isinstance(obj, np.ndarray):\n",
    "        print(obj.shape)\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "    else:\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "            \n",
    "def DS(obj, label=None):\n",
    "    D(obj, label, c=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0aa18d7-acb5-412f-8495-8483dbe71a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceTensor:\n",
    "    def __init__(self):\n",
    "        print('Initializing model...')\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map='auto',\n",
    "            trust_remote_code=True,\n",
    "            use_cache=True,\n",
    "            # attn_implementation='flash_attention_2',\n",
    "        )\n",
    "        print('Initializing tokenizer...')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.batch_size = 8\n",
    "        \n",
    "    def candidates_generator(self, top_p: float, max_beams: int, max_new_tokens: int, prompt: str):\n",
    "        print(prompt)\n",
    "        candidates, candidate_logprobs = self._init_candidates(prompt)\n",
    "        for level_idx in range(max_new_tokens):\n",
    "            logits, embeddings = self._infer(candidates, candidate_logprobs)\n",
    "        \n",
    "            if candidates.shape[0] > max_beams:\n",
    "                candidates, candidate_parents, candidate_aunts, candidate_logprobs, logits = self._k_means(logits, embeddings, candidates, candidate_logprobs, max_beams)\n",
    "                yield self._format_k_means(level_idx, candidates, candidate_parents, candidate_aunts, candidate_logprobs)\n",
    "\n",
    "            candidates, candidate_parents, candidate_logprobs = self._top_p(logits, candidates, candidate_logprobs, top_p)\n",
    "            yield self._format_top_p(level_idx, candidates, candidate_parents, candidate_logprobs)\n",
    "\n",
    "        yield f\"event: message\\nid: END\\ndata: []\\n\\n\"\n",
    "\n",
    "    def _format_k_means(self, level_idx, candidates, candidate_parents, candidate_aunts, candidate_logprobs):\n",
    "        candidate_texts = self.tokenizer.batch_decode(candidates[:, -1])\n",
    "        candidate_probs = candidate_logprobs.exp()\n",
    "        candidate_dicts = []\n",
    "        idx = f\"{level_idx}-k\"\n",
    "        for i in range(len(candidate_texts)):\n",
    "            candidate_dicts.append({'content': candidate_texts[i], 'parent': candidate_parents[i], 'aunts': candidate_aunts[i], 'prob': candidate_probs[i].item()})\n",
    "        data = json.dumps({'id': idx, 'level_type': 'k_means', 'nodes': candidate_dicts})\n",
    "        return f\"event: message\\nid: {idx}\\\"\\ndata: {data}\\n\\n\"\n",
    "\n",
    "    def _format_top_p(self, level_idx, candidates, candidate_parents, candidate_logprobs):\n",
    "        candidate_texts = self.tokenizer.batch_decode(candidates[:, -1])\n",
    "        candidate_probs = candidate_logprobs.exp()\n",
    "        candidate_dicts = []\n",
    "        idx = f\"{level_idx}-p\"\n",
    "        for i in range(len(candidate_texts)):\n",
    "            candidate_dicts.append({'content': candidate_texts[i], 'parent': candidate_parents[i], 'prob': candidate_probs[i].item()})\n",
    "        data = json.dumps({'id': idx, 'level_type': 'top_p', 'nodes': candidate_dicts})\n",
    "        return f\"event: message\\nid: {idx}\\ndata: {data}\\n\\n\"\n",
    "\n",
    "\n",
    "    def _init_candidates(self, text: str):\n",
    "        prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "        inputs = self.tokenizer(prompt, return_tensors='pt')\n",
    "        D(inputs.input_ids, 'input_ids')\n",
    "        print(self.tokenizer.batch_decode(inputs.input_ids))\n",
    "\n",
    "        candidates = inputs.input_ids.to(self.device)\n",
    "        candidate_logprobs = torch.zeros((1), dtype=torch.float32, device=self.device)\n",
    "\n",
    "        return candidates, candidate_logprobs\n",
    "\n",
    "    def _k_means(self, logits, embeddings, candidates, candidate_logprobs, max_beams):\n",
    "        D(candidates, 'candidates')\n",
    "        D(candidate_logprobs, 'candidate_logprobs')\n",
    "        # === CPU ===\n",
    "        embeddings_np = embeddings.float().numpy(force=True)\n",
    "        D(embeddings_np, 'embeddings_np')\n",
    "        k_means = KMeans(n_clusters=min(2, embeddings_np.shape[0]), random_state=0, n_init=\"auto\")\n",
    "        k_mean_space = k_means.fit_transform(embeddings_np)\n",
    "        D(k_mean_space, 'k_mean_space')\n",
    "        k_mean_clusters = k_means.predict(embeddings_np)\n",
    "        D(k_mean_clusters, 'k_mean_clusters')\n",
    "        k_mean_logprob_mass = np.log(np.bincount(k_mean_clusters, weights=candidate_logprobs.cpu().exp()))\n",
    "        D(k_mean_logprob_mass, 'k_mean_logprob_mass')\n",
    "        closest = np.argmin(k_mean_space, axis=0)\n",
    "        D(closest, 'closest')\n",
    "        # === END CPU ===\n",
    "        \n",
    "        closest_indices = torch.from_numpy(closest).to(self.device)\n",
    "        new_candidates = candidates.index_select(0, closest_indices)\n",
    "        D(new_candidates, 'new_candidates')\n",
    "        new_candidate_parents = closest_indices.tolist()\n",
    "        D(new_candidate_parents, 'new_candidate_parents')\n",
    "        new_candidate_aunts = [torch.nonzero(torch.from_numpy(k_mean_clusters).to(self.device) == i).squeeze(-1).tolist() for i in range(new_candidates.shape[0])]\n",
    "        D(new_candidate_aunts, 'new_candidate_aunts')\n",
    "        new_candidate_logprobs = torch.from_numpy(k_mean_logprob_mass).to(self.device)\n",
    "        D(new_candidate_logprobs, 'new_candidate_logprobs')\n",
    "        new_candidate_logits = logits.index_select(0, closest_indices)\n",
    "        \n",
    "        return new_candidates, new_candidate_parents, new_candidate_aunts, new_candidate_logprobs, new_candidate_logits\n",
    "        \n",
    "    def _top_p(self, logits, candidates, candidate_logprobs, top_p):\n",
    "        D(candidates, 'candidates')\n",
    "        D(candidate_logprobs, 'candidate_logprobs')\n",
    "        \n",
    "        last_tok_logits = logits[:, -1, :]\n",
    "        D(last_tok_logits, 'last_tok_logits')\n",
    "\n",
    "        sorted_logits, sorted_indices = torch.sort(last_tok_logits, descending=True, dim=-1)\n",
    "        DS(sorted_logits, 'sorted_logits')\n",
    "        DS(sorted_indices, 'sorted_indices')\n",
    "        sorted_probs = F.softmax(sorted_logits, dim=-1)\n",
    "        D(sorted_probs, 'sorted_probs')\n",
    "        display(sorted_probs.sum(dim=1))\n",
    "        cum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        D(cum_probs, 'cum_probs')\n",
    "\n",
    "        # Create tensor of bools indicating which indices are cumulatively less than top_p\n",
    "        keep_indices = cum_probs < top_p\n",
    "\n",
    "        # Keep the last element that went over top_p\n",
    "        keep_indices[:, 1:] = keep_indices[:, :-1].clone() # Is this inefficient?\n",
    "        keep_indices[:, 0] = 1  # Always keep the first element\n",
    "        D(keep_indices, 'keep_indices')\n",
    "\n",
    "        new_candidate_parents = keep_indices.nonzero()[:, 0]\n",
    "        D(new_candidate_parents, 'new_candidate_parents')\n",
    "\n",
    "        # OPTIM: Potential optimization -- have a fixed tensor of size (max_candidates, max_tokens) and copy this into that (batch-aware).\n",
    "        # OPTIM: consider which of these operations can be done in-place to prevent new allocations?\n",
    "        carryover_candidates = candidates.index_select(0, new_candidate_parents)\n",
    "        D(carryover_candidates, 'carryover_candidates')\n",
    "\n",
    "        # Similar code could be used to trace entire origin of sequence. For now since server just traces parent of the preceding generation, not needed\n",
    "        # carryover_candidate_parents = candidate_parents.index_select(0, carryover_candidate_indices)  # Not strictly necessary since 1d\n",
    "        # D(carryover_candidate_parents, 'carryover_candidate_parents')\n",
    "\n",
    "        carryover_candidate_logprobs = candidate_logprobs.index_select(0, new_candidate_parents)  # Not strictly necessary since 1d\n",
    "        D(carryover_candidate_logprobs, 'carryover_candidate_logprobs')\n",
    "\n",
    "        new_candidate_toks = sorted_indices[keep_indices].unsqueeze(1)\n",
    "        D(new_candidate_toks, 'new_candidate_toks')\n",
    "        new_candidate_tok_logprobs = sorted_probs[keep_indices].log()\n",
    "        D(new_candidate_tok_logprobs, 'new_candidate_tok_logprobs')\n",
    "\n",
    "        new_candidates = torch.cat([carryover_candidates, new_candidate_toks], dim=1)\n",
    "        D(new_candidates, 'new_candidates')\n",
    "        new_candidate_logprobs = carryover_candidate_logprobs.add_(new_candidate_tok_logprobs)\n",
    "        D(new_candidate_logprobs, 'new_candidate_logprobs')\n",
    "\n",
    "        return new_candidates, new_candidate_parents.tolist(), new_candidate_logprobs\n",
    "\n",
    "\n",
    "    def _infer(self, candidates, candidate_logprobs):\n",
    "        with torch.inference_mode():\n",
    "            num_batches = (candidates.shape[0] + self.batch_size - 1) // self.batch_size  # Round up to nearest whole number of batches\n",
    "            D(num_batches, 'num_batches')\n",
    "\n",
    "            check_gpu('infer start')\n",
    "            output_logits_list = []\n",
    "            output_embeddings_list = []\n",
    "            for i in range(0, num_batches, 1):\n",
    "                batch_candidates = candidates[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                DS(batch_candidates, 'batch_candidates')\n",
    "                batch_candidate_logprobs = candidate_logprobs[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                DS(batch_candidate_logprobs, 'batch_candidate_logprobs')\n",
    "\n",
    "                batch_outputs = self.model(input_ids=batch_candidates, output_hidden_states=True)\n",
    "                DS(batch_outputs.logits, 'batch_logits')\n",
    "                DS(batch_outputs.hidden_states[-1], 'hidden_states[-1]')\n",
    "\n",
    "                output_logits_list.append(batch_outputs.logits)\n",
    "                output_embeddings_list.append(batch_outputs.hidden_states[-1][:,-1,:])\n",
    "                check_gpu('infer - after batch run')\n",
    "\n",
    "            output_logits = torch.cat(output_logits_list, dim=0)\n",
    "            output_embeddings = torch.cat(output_embeddings_list, dim=0)\n",
    "            \n",
    "            return output_logits, output_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "669a1b7d-de91-4218-a4b2-64a32b68665c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.d269012bea6fbe38ce7752c8940fea010eea3383.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.d269012bea6fbe38ce7752c8940fea010eea3383.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c07fc63289482aad388958ff123d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer...\n",
      "What is the highest mountain?\n",
      "\n",
      "input_ids\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s><|user|> What is the highest mountain? <|end|><|assistant|>']\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 14579 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 11])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 11, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 11, 3072])\n",
      "infer - after batch run: GPU memory used: 14583 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7812, -1.4688, -3.2969,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.2405e-01, 7.5850e-02, 8.8812e-05,  ..., 1.1622e-21, 7.0490e-22,\n",
       "         3.7730e-22]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9240, 0.9999, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 0-p\n",
      "data: {\"id\": \"0-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"The\", \"parent\": 0, \"prob\": 0.924048125743866}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 14583 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 12])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 12, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 12, 3072])\n",
      "infer - after batch run: GPU memory used: 14583 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2969,  1.0312, -5.0938,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9909e-01, 9.1105e-04, 1.2088e-06,  ..., 6.5938e-24, 3.9993e-24,\n",
       "         1.4713e-24]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9991, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0009], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([1, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0799], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 1-p\n",
      "data: {\"id\": \"1-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"highest\", \"parent\": 0, \"prob\": 0.9232035875320435}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 14583 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 13])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 13, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 13, 3072])\n",
      "infer - after batch run: GPU memory used: 14585 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0799], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8906,  3.1875, -7.0938,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9984e-01, 1.2339e-04, 3.5352e-05,  ..., 5.1391e-24, 4.5352e-24,\n",
       "         3.5320e-24]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9998, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([1, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0799], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0002], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([1, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0801], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 2-p\n",
      "data: {\"id\": \"2-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"mountain\", \"parent\": 0, \"prob\": 0.9230522513389587}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 14585 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 14])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 14, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 14, 3072])\n",
      "infer - after batch run: GPU memory used: 14585 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0801], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.8125,  1.2734, -5.8750,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[8.1600e-01, 9.7458e-02, 8.6006e-02,  ..., 5.2119e-21, 4.0591e-21,\n",
       "         1.6921e-21]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8160, 0.9135, 0.9995,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([2, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0801, -0.0801], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[373],\n",
       "        [297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2033, -2.3283], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.4084], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 3-p\n",
      "data: {\"id\": \"3-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"on\", \"parent\": 0, \"prob\": 0.7532129883766174}, {\"content\": \"in\", \"parent\": 0, \"prob\": 0.08995844423770905}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 14585 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([2, 15])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([2])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([2, 15, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([2, 15, 3072])\n",
      "infer - after batch run: GPU memory used: 14603 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.4084], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6797,  0.8750, -4.7812,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 3.3438, -5.4688, -4.6875,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9996e-01, 3.5356e-05, 1.7603e-06,  ..., 3.5325e-24, 2.4278e-24,\n",
       "         3.7232e-25],\n",
       "        [8.1683e-01, 1.8226e-01, 5.1193e-04,  ..., 3.4021e-20, 3.4021e-20,\n",
       "         7.5910e-21]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.8168, 0.9991, 0.9996,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([3, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.4084, -2.4084], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11563],\n",
       "        [ 4958],\n",
       "        [  278]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-3.7432e-05, -2.0232e-01, -1.7023e+00], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([3, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,   278]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.6107, -4.1107], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 4-p\n",
      "data: {\"id\": \"4-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"Earth\", \"parent\": 0, \"prob\": 0.7531847953796387}, {\"content\": \"terms\", \"parent\": 1, \"prob\": 0.0734809935092926}, {\"content\": \"the\", \"parent\": 1, \"prob\": 0.016395829617977142}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 14603 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([3, 16])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([3])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([3, 16, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([3, 16, 3072])\n",
      "infer - after batch run: GPU memory used: 14619 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([3, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,   278]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.6107, -4.1107], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embeddings_np\n",
      "(3, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.4765625 , -0.0112915 ,  1.4921875 , ..., -0.94921875,\n",
       "        -0.27734375, -1.515625  ],\n",
       "       [ 0.640625  , -1.109375  ,  2.71875   , ..., -0.9140625 ,\n",
       "         2.5625    , -2.1875    ],\n",
       "       [ 0.09326172, -0.6796875 ,  3.390625  , ..., -0.69921875,\n",
       "        -3.28125   , -1.0859375 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_space\n",
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[105.234764,  50.63994 ],\n",
       "       [  0.      ,  93.1218  ],\n",
       "       [106.760445,  50.63994 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_clusters\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_logprob_mass\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.6107285 , -0.26190956])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "closest\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_aunts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1], [0, 2]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -0.2619], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 5-k\"\n",
      "data: {\"id\": \"5-k\", \"level_type\": \"k_means\", \"nodes\": [{\"content\": \"terms\", \"parent\": 1, \"aunts\": [1], \"prob\": 0.07348099350929262}, {\"content\": \"Earth\", \"parent\": 0, \"aunts\": [0, 2], \"prob\": 0.7695806249976158}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -0.2619], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1.5703,  -2.2031,  -5.8750,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [ -0.9766,  -6.3438, -10.3125,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 4.0587e-10, 1.3177e-10,  ..., 1.3697e-25, 1.2088e-25,\n",
       "         1.0668e-25],\n",
       "        [9.8127e-01, 1.5861e-02, 2.1465e-03,  ..., 8.4822e-22, 5.8297e-22,\n",
       "         1.6702e-22]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.9813, 0.9971, 0.9993,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -0.2619], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  310],\n",
       "        [29892]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, -0.0189], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -0.2808], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 5-p\n",
      "data: {\"id\": \"5-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"of\", \"parent\": 0, \"prob\": 0.07348099350929262}, {\"content\": \",\", \"parent\": 1, \"prob\": 0.7551670331892734}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "event: message\n",
      "id: END\n",
      "data: []\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "it = InferenceTensor()\n",
    "\n",
    "for x in it.candidates_generator(0.9, 2, 6, 'What is the highest mountain?'):\n",
    "    print(x)\n",
    "    print()\n",
    "    print('====================================')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
