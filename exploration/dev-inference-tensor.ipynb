{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20264819-2d9c-40f4-9fcc-a2b7b019321c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.31.0)\n",
      "Requirement already satisfied: optimum in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.20.0)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (12.535.133)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.23.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: coloredlogs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optimum) (2.19.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers[sentencepiece]<4.42.0,>=4.26.0->optimum) (4.25.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets->optimum) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets->optimum) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->optimum) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate optimum nvidia-ml-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d0609e-c769-43dc-926b-f5b41beda157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5d6897a1f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.utils import is_flash_attn_2_available\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import json\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9112e61-a3e7-4ea5-853e-f27145f37e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from pynvml import *\n",
    "\n",
    "def check_gpu(step):\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"{step}: GPU memory used: {info.used // 1024**2} MB.\")\n",
    "    \n",
    "def D(obj, label=None, c=True):\n",
    "    print()\n",
    "    if label:\n",
    "        print(label)\n",
    "        \n",
    "    if isinstance(obj, tuple):\n",
    "        print(len(obj))\n",
    "    elif isinstance(obj, torch.Tensor) or isinstance(obj, np.ndarray):\n",
    "        print(obj.shape)\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "    else:\n",
    "        if c: # Contents\n",
    "            display(obj)\n",
    "            \n",
    "def DS(obj, label=None):\n",
    "    D(obj, label, c=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0aa18d7-acb5-412f-8495-8483dbe71a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class InferenceTensor:\n",
    "    def __init__(self):\n",
    "        print('Initializing model...')\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map='auto',\n",
    "            trust_remote_code=True,\n",
    "            use_cache=True,\n",
    "            # attn_implementation='flash_attention_2',\n",
    "        )\n",
    "        print('Initializing tokenizer...')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"microsoft/Phi-3-mini-4k-instruct\")\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        self.max_new_tokens = 10\n",
    "        self.batch_size = 8\n",
    "        \n",
    "    def candidates_generator(self, top_p: float, max_beams: int, prompt: str):\n",
    "        print(prompt)\n",
    "        candidates, candidate_logprobs = self._init_candidates(prompt)\n",
    "        for level_idx in range(self.max_new_tokens):\n",
    "            logits, embeddings = self._infer(candidates, candidate_logprobs)\n",
    "        \n",
    "            if candidates.shape[0] > max_beams:\n",
    "                candidates, candidate_parents, candidate_aunts, candidate_logprobs, logits = self._k_means(logits, embeddings, candidates, candidate_logprobs, max_beams)\n",
    "                yield self._format_k_means(level_idx, candidates, candidate_parents, candidate_aunts, candidate_logprobs)\n",
    "\n",
    "            candidates, candidate_parents, candidate_logprobs = self._top_p(logits, candidates, candidate_logprobs, top_p)\n",
    "            yield self._format_top_p(level_idx, candidates, candidate_parents, candidate_logprobs)\n",
    "\n",
    "        yield f\"event: message\\nid: END\\ndata: []\\n\\n\"\n",
    "\n",
    "    def _format_k_means(self, level_idx, candidates, candidate_parents, candidate_aunts, candidate_logprobs):\n",
    "        candidate_texts = self.tokenizer.batch_decode(candidates[:, -1])\n",
    "        candidate_probs = candidate_logprobs.exp()\n",
    "        candidate_dicts = []\n",
    "        idx = f\"{level_idx}-k\"\n",
    "        for i in range(len(candidate_texts)):\n",
    "            candidate_dicts.append({'content': candidate_texts[i], 'parent': candidate_parents[i], 'aunts': candidate_aunts[i], 'prob': candidate_probs[i].item()})\n",
    "        data = json.dumps({'id': idx, 'level_type': 'k_means', 'nodes': candidate_dicts})\n",
    "        return f\"event: message\\nid: {idx}\\\"\\ndata: {data}\\n\\n\"\n",
    "\n",
    "    def _format_top_p(self, level_idx, candidates, candidate_parents, candidate_logprobs):\n",
    "        candidate_texts = self.tokenizer.batch_decode(candidates[:, -1])\n",
    "        candidate_probs = candidate_logprobs.exp()\n",
    "        candidate_dicts = []\n",
    "        idx = f\"{level_idx}-p\"\n",
    "        for i in range(len(candidate_texts)):\n",
    "            candidate_dicts.append({'content': candidate_texts[i], 'parent': candidate_parents[i], 'prob': candidate_probs[i].item()})\n",
    "        data = json.dumps({'id': idx, 'level_type': 'top_p', 'nodes': candidate_dicts})\n",
    "        return f\"event: message\\nid: {idx}\\ndata: {data}\\n\\n\"\n",
    "\n",
    "\n",
    "    def _init_candidates(self, text: str):\n",
    "        prompt = \"<|user|>\\n{} <|end|>\\n<|assistant|>\".format(text)\n",
    "        inputs = self.tokenizer(prompt, return_tensors='pt')\n",
    "        D(inputs.input_ids, 'input_ids')\n",
    "        print(self.tokenizer.batch_decode(inputs.input_ids))\n",
    "\n",
    "        candidates = inputs.input_ids.to(self.device)\n",
    "        candidate_logprobs = torch.zeros((1), dtype=torch.float32, device=self.device)\n",
    "\n",
    "        return candidates, candidate_logprobs\n",
    "\n",
    "    def _k_means(self, logits, embeddings, candidates, candidate_logprobs, max_beams):\n",
    "        D(candidates, 'candidates')\n",
    "        D(candidate_logprobs, 'candidate_logprobs')\n",
    "        # === CPU ===\n",
    "        embeddings_np = embeddings.float().numpy(force=True)\n",
    "        D(embeddings_np, 'embeddings_np')\n",
    "        k_means = KMeans(n_clusters=min(2, embeddings_np.shape[0]), random_state=0, n_init=\"auto\")\n",
    "        k_mean_space = k_means.fit_transform(embeddings_np)\n",
    "        D(k_mean_space, 'k_mean_space')\n",
    "        k_mean_clusters = k_means.predict(embeddings_np)\n",
    "        D(k_mean_clusters, 'k_mean_clusters')\n",
    "        k_mean_logprob_mass = np.bincount(k_mean_clusters, weights=candidate_logprobs.cpu())\n",
    "        D(k_mean_logprob_mass, 'k_mean_logprob_mass')\n",
    "        closest = np.argmin(k_mean_space, axis=0)\n",
    "        D(closest, 'closest')\n",
    "        # === END CPU ===\n",
    "        \n",
    "        closest_indices = torch.from_numpy(closest).to(self.device)\n",
    "        new_candidates = candidates.index_select(0, closest_indices)\n",
    "        D(new_candidates, 'new_candidates')\n",
    "        new_candidate_parents = closest_indices.tolist()\n",
    "        D(new_candidate_parents, 'new_candidate_parents')\n",
    "        new_candidate_aunts = [torch.nonzero(torch.from_numpy(k_mean_clusters).to(self.device) == i).squeeze(-1).tolist() for i in range(new_candidates.shape[0])]\n",
    "        D(new_candidate_aunts, 'new_candidate_aunts')\n",
    "        new_candidate_logprobs = torch.from_numpy(k_mean_logprob_mass).to(self.device)\n",
    "        D(new_candidate_logprobs, 'new_candidate_logprobs')\n",
    "        new_candidate_logits = logits.index_select(0, closest_indices)\n",
    "        \n",
    "        return new_candidates, new_candidate_parents, new_candidate_aunts, new_candidate_logprobs, new_candidate_logits\n",
    "        \n",
    "    def _top_p(self, logits, candidates, candidate_logprobs, top_p):\n",
    "        D(candidates, 'candidates')\n",
    "        D(candidate_logprobs, 'candidate_logprobs')\n",
    "        \n",
    "        last_tok_logits = logits[:, -1, :]\n",
    "        D(last_tok_logits, 'last_tok_logits')\n",
    "\n",
    "        sorted_logits, sorted_indices = torch.sort(last_tok_logits, descending=True, dim=-1)\n",
    "        DS(sorted_logits, 'sorted_logits')\n",
    "        DS(sorted_indices, 'sorted_indices')\n",
    "        sorted_probs = F.softmax(sorted_logits, dim=-1)\n",
    "        D(sorted_probs, 'sorted_probs')\n",
    "        display(sorted_probs.sum(dim=1))\n",
    "        cum_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "        D(cum_probs, 'cum_probs')\n",
    "\n",
    "        # Create tensor of bools indicating which indices are cumulatively less than top_p\n",
    "        keep_indices = cum_probs < top_p\n",
    "\n",
    "        # Keep the last element that went over top_p\n",
    "        keep_indices[:, 1:] = keep_indices[:, :-1].clone() # Is this inefficient?\n",
    "        keep_indices[:, 0] = 1  # Always keep the first element\n",
    "        D(keep_indices, 'keep_indices')\n",
    "\n",
    "        new_candidate_parents = keep_indices.nonzero()[:, 0]\n",
    "        D(new_candidate_parents, 'new_candidate_parents')\n",
    "\n",
    "        # OPTIM: Potential optimization -- have a fixed tensor of size (max_candidates, max_tokens) and copy this into that (batch-aware).\n",
    "        # OPTIM: consider which of these operations can be done in-place to prevent new allocations?\n",
    "        carryover_candidates = candidates.index_select(0, new_candidate_parents)\n",
    "        D(carryover_candidates, 'carryover_candidates')\n",
    "\n",
    "        # Similar code could be used to trace entire origin of sequence. For now since server just traces parent of the preceding generation, not needed\n",
    "        # carryover_candidate_parents = candidate_parents.index_select(0, carryover_candidate_indices)  # Not strictly necessary since 1d\n",
    "        # D(carryover_candidate_parents, 'carryover_candidate_parents')\n",
    "\n",
    "        carryover_candidate_logprobs = candidate_logprobs.index_select(0, new_candidate_parents)  # Not strictly necessary since 1d\n",
    "        D(carryover_candidate_logprobs, 'carryover_candidate_logprobs')\n",
    "\n",
    "        new_candidate_toks = sorted_indices[keep_indices].unsqueeze(1)\n",
    "        D(new_candidate_toks, 'new_candidate_toks')\n",
    "        new_candidate_tok_logprobs = sorted_probs[keep_indices].log()\n",
    "        D(new_candidate_tok_logprobs, 'new_candidate_tok_logprobs')\n",
    "\n",
    "        new_candidates = torch.cat([carryover_candidates, new_candidate_toks], dim=1)\n",
    "        D(new_candidates, 'new_candidates')\n",
    "        new_candidate_logprobs = carryover_candidate_logprobs.add_(new_candidate_tok_logprobs)\n",
    "        D(new_candidate_logprobs, 'new_candidate_logprobs')\n",
    "\n",
    "        return new_candidates, new_candidate_parents.tolist(), new_candidate_logprobs\n",
    "\n",
    "\n",
    "    def _infer(self, candidates, candidate_logprobs):\n",
    "        with torch.inference_mode():\n",
    "            num_batches = (candidates.shape[0] + self.batch_size - 1) // self.batch_size  # Round up to nearest whole number of batches\n",
    "            D(num_batches, 'num_batches')\n",
    "\n",
    "            check_gpu('infer start')\n",
    "            output_logits_list = []\n",
    "            output_embeddings_list = []\n",
    "            for i in range(0, num_batches, 1):\n",
    "                batch_candidates = candidates[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                DS(batch_candidates, 'batch_candidates')\n",
    "                batch_candidate_logprobs = candidate_logprobs[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                DS(batch_candidate_logprobs, 'batch_candidate_logprobs')\n",
    "\n",
    "                batch_outputs = self.model(input_ids=batch_candidates, output_hidden_states=True)\n",
    "                DS(batch_outputs.logits, 'batch_logits')\n",
    "                DS(batch_outputs.hidden_states[-1], 'hidden_states[-1]')\n",
    "\n",
    "                output_logits_list.append(batch_outputs.logits)\n",
    "                output_embeddings_list.append(batch_outputs.hidden_states[-1][:,-1,:])\n",
    "                check_gpu('infer - after batch run')\n",
    "\n",
    "            output_logits = torch.cat(output_logits_list, dim=0)\n",
    "            output_embeddings = torch.cat(output_embeddings_list, dim=0)\n",
    "            \n",
    "            return output_logits, output_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669a1b7d-de91-4218-a4b2-64a32b68665c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7525a7620b49e5bb48a3ca6f4d7df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer...\n",
      "What is the highest mountain?\n",
      "\n",
      "input_ids\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s><|user|> What is the highest mountain? <|end|><|assistant|>']\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15175 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 11])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 11, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 11, 3072])\n",
      "infer - after batch run: GPU memory used: 15179 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7812, -1.4688, -3.2969,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.2405e-01, 7.5850e-02, 8.8812e-05,  ..., 1.1622e-21, 7.0490e-22,\n",
       "         3.7730e-22]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9240, 0.9999, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([1, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 0-p\n",
      "data: {\"id\": \"0-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"The\", \"parent\": 0, \"prob\": 0.924048125743866}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15179 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 12])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 12, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 12, 3072])\n",
      "infer - after batch run: GPU memory used: 15179 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2969,  1.0312, -5.0938,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9909e-01, 9.1105e-04, 1.2088e-06,  ..., 6.5938e-24, 3.9993e-24,\n",
       "         1.4713e-24]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9991, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([1, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0790], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0009], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([1, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0799], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 1-p\n",
      "data: {\"id\": \"1-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"highest\", \"parent\": 0, \"prob\": 0.9232035875320435}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15179 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 13])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 13, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 13, 3072])\n",
      "infer - after batch run: GPU memory used: 15181 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0799], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8906,  3.1875, -7.0938,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9984e-01, 1.2339e-04, 3.5352e-05,  ..., 5.1391e-24, 4.5352e-24,\n",
       "         3.5320e-24]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9998, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([1, 13])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0799], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0002], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([1, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0801], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 2-p\n",
      "data: {\"id\": \"2-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"mountain\", \"parent\": 0, \"prob\": 0.9230522513389587}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15181 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([1, 14])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([1])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([1, 14, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([1, 14, 3072])\n",
      "infer - after batch run: GPU memory used: 15181 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([1, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0801], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.8125,  1.2734, -5.8750,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([1, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[8.1600e-01, 9.7458e-02, 8.6006e-02,  ..., 5.2119e-21, 4.0591e-21,\n",
       "         1.6921e-21]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.8160, 0.9135, 0.9995,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([1, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([2, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0801, -0.0801], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[373],\n",
       "        [297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2033, -2.3283], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.4084], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 3-p\n",
      "data: {\"id\": \"3-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"on\", \"parent\": 0, \"prob\": 0.7532129883766174}, {\"content\": \"in\", \"parent\": 0, \"prob\": 0.08995844423770905}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15181 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([2, 15])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([2])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([2, 15, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([2, 15, 3072])\n",
      "infer - after batch run: GPU memory used: 15199 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.4084], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6797,  0.8750, -4.7812,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 3.3438, -5.4688, -4.6875,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9996e-01, 3.5356e-05, 1.7603e-06,  ..., 3.5325e-24, 2.4278e-24,\n",
       "         3.7232e-25],\n",
       "        [8.1683e-01, 1.8226e-01, 5.1193e-04,  ..., 3.4021e-20, 3.4021e-20,\n",
       "         7.5910e-21]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.8168, 0.9991, 0.9996,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([3, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.4084, -2.4084], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([3, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11563],\n",
       "        [ 4958],\n",
       "        [  278]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-3.7432e-05, -2.0232e-01, -1.7023e+00], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([3, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,   278]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.6107, -4.1107], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 4-p\n",
      "data: {\"id\": \"4-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"Earth\", \"parent\": 0, \"prob\": 0.7531847953796387}, {\"content\": \"terms\", \"parent\": 1, \"prob\": 0.0734809935092926}, {\"content\": \"the\", \"parent\": 1, \"prob\": 0.016395829617977142}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15219 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([3, 16])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([3])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([3, 16, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([3, 16, 3072])\n",
      "infer - after batch run: GPU memory used: 15235 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([3, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,   278]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.2834, -2.6107, -4.1107], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embeddings_np\n",
      "(3, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.4765625 , -0.0112915 ,  1.4921875 , ..., -0.94921875,\n",
       "        -0.27734375, -1.515625  ],\n",
       "       [ 0.640625  , -1.109375  ,  2.71875   , ..., -0.9140625 ,\n",
       "         2.5625    , -2.1875    ],\n",
       "       [ 0.09326172, -0.6796875 ,  3.390625  , ..., -0.69921875,\n",
       "        -3.28125   , -1.0859375 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_space\n",
      "(3, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[105.234764,  50.63994 ],\n",
       "       [  0.      ,  93.1218  ],\n",
       "       [106.760445,  50.63994 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_clusters\n",
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_logprob_mass\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-2.6107285 , -4.39417294])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "closest\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_aunts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1], [0, 2]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -4.3942], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 5-k\"\n",
      "data: {\"id\": \"5-k\", \"level_type\": \"k_means\", \"nodes\": [{\"content\": \"terms\", \"parent\": 1, \"aunts\": [1], \"prob\": 0.07348099318896636}, {\"content\": \"Earth\", \"parent\": 0, \"aunts\": [0, 2], \"prob\": 0.012349089582051961}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -4.3942], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1.5703,  -2.2031,  -5.8750,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [ -0.9766,  -6.3438, -10.3125,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 4.0587e-10, 1.3177e-10,  ..., 1.3697e-25, 1.2088e-25,\n",
       "         1.0668e-25],\n",
       "        [9.8127e-01, 1.5861e-02, 2.1465e-03,  ..., 8.4822e-22, 5.8297e-22,\n",
       "         1.6702e-22]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.9813, 0.9971, 0.9993,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([2, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -4.3942], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  310],\n",
       "        [29892]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000, -0.0189], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -4.4131], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 5-p\n",
      "data: {\"id\": \"5-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"of\", \"parent\": 0, \"prob\": 0.07348099318896636}, {\"content\": \",\", \"parent\": 1, \"prob\": 0.012117801617336242}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15235 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([2, 17])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([2])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([2, 17, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([2, 17, 3072])\n",
      "infer - after batch run: GPU memory used: 15235 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -4.4131], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0.2129,  -0.4570,  -6.7500,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [ -3.5469,  -2.0000, -10.3750,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.9407e-01, 1.8615e-01, 1.8615e-01,  ..., 1.0154e-18, 6.1589e-19,\n",
       "         5.4352e-19],\n",
       "        [4.0809e-01, 3.1782e-01, 2.1843e-01,  ..., 1.1798e-19, 8.6316e-20,\n",
       "         7.6173e-20]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.3941, 0.5802, 0.7664,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.4081, 0.7259, 0.9443,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([10, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.6107, -2.6107, -2.6107, -2.6107, -2.6107, -2.6107, -2.6107, -4.4131,\n",
       "        -4.4131, -4.4131], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([10, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[11858],\n",
       "        [ 3171],\n",
       "        [19224],\n",
       "        [ 2038],\n",
       "        [  967],\n",
       "        [ 2533],\n",
       "        [11563],\n",
       "        [  408],\n",
       "        [ 2729],\n",
       "        [  297]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.9312, -1.6812, -1.6812, -3.0562, -3.3062, -3.3062, -3.5562, -0.8963,\n",
       "        -1.1463, -1.5213], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([10, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,  3171],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,  2038],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,   967],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,  2533],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11563],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892,   408],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892,  2729],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892,   297]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-3.5420, -4.2920, -4.2920, -5.6670, -5.9170, -5.9170, -6.1670, -5.3094,\n",
       "        -5.5594, -5.9344], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 6-p\n",
      "data: {\"id\": \"6-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"elev\", \"parent\": 0, \"prob\": 0.02895674790207378}, {\"content\": \"height\", \"parent\": 0, \"prob\": 0.013678199185093203}, {\"content\": \"peak\", \"parent\": 0, \"prob\": 0.013678199185093203}, {\"content\": \"above\", \"parent\": 0, \"prob\": 0.0034583899410235456}, {\"content\": \"its\", \"parent\": 0, \"prob\": 0.002693396794235407}, {\"content\": \"sum\", \"parent\": 0, \"prob\": 0.002693396794235407}, {\"content\": \"Earth\", \"parent\": 0, \"prob\": 0.0020976195324725463}, {\"content\": \"as\", \"parent\": 1, \"prob\": 0.00494511213828901}, {\"content\": \"based\", \"parent\": 1, \"prob\": 0.0038512569761225794}, {\"content\": \"in\", \"parent\": 1, \"prob\": 0.002646927945096369}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15235 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([8, 18])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([8])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([8, 18, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([8, 18, 3072])\n",
      "infer - after batch run: GPU memory used: 15353 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([2, 18])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([2])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([2, 18, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([2, 18, 3072])\n",
      "infer - after batch run: GPU memory used: 15381 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([10, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,  3171],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,  2038],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,   967],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310,  2533],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11563],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892,   408],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892,  2729],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   373, 11563, 29892,   297]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-3.5420, -4.2920, -4.2920, -5.6670, -5.9170, -5.9170, -6.1670, -5.3094,\n",
       "        -5.5594, -5.9344], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embeddings_np\n",
      "(10, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.5625    , -2.265625  ,  1.78125   , ...,  1.15625   ,\n",
       "         1.265625  , -0.3515625 ],\n",
       "       [-0.71484375,  0.29296875,  3.296875  , ...,  0.05078125,\n",
       "         1.15625   , -0.35546875],\n",
       "       [-0.75      , -1.2109375 ,  3.328125  , ...,  0.03637695,\n",
       "        -1.0546875 , -0.5078125 ],\n",
       "       ...,\n",
       "       [-1.1328125 ,  0.54296875,  0.23242188, ..., -1.6953125 ,\n",
       "         1.109375  , -5.3125    ],\n",
       "       [ 0.51171875, -1.3359375 ,  0.40625   , ...,  0.41601562,\n",
       "         0.46289062, -3.9375    ],\n",
       "       [-2.484375  , -0.44921875,  2.4375    , ...,  0.34375   ,\n",
       "        -2.703125  , -4.28125   ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_space\n",
      "(10, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[51.670624, 84.66034 ],\n",
       "       [87.51908 , 61.940083],\n",
       "       [85.87011 , 58.84681 ],\n",
       "       [92.760315, 71.27328 ],\n",
       "       [89.12618 , 60.97973 ],\n",
       "       [51.670624, 82.49791 ],\n",
       "       [90.98064 , 63.01418 ],\n",
       "       [97.24759 , 67.10196 ],\n",
       "       [97.51835 , 69.43807 ],\n",
       "       [94.846634, 62.403366]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_clusters\n",
      "(10,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_logprob_mass\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -9.45890415, -43.13782734])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "closest\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_aunts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 5], [1, 2, 3, 4, 6, 7, 8, 9]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ -9.4589, -43.1378], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 7-k\"\n",
      "data: {\"id\": \"7-k\", \"level_type\": \"k_means\", \"nodes\": [{\"content\": \"elev\", \"parent\": 0, \"aunts\": [0, 5], \"prob\": 7.799201197092837e-05}, {\"content\": \"peak\", \"parent\": 2, \"aunts\": [1, 2, 3, 4, 6, 7, 8, 9], \"prob\": 1.8428060336253292e-19}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ -9.4589, -43.1378], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7148, -1.0703, -1.1406,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.1250, -1.9844, -7.7188,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9999e-01, 7.8892e-06, 1.9947e-06,  ..., 2.6103e-23, 1.5832e-23,\n",
       "         6.5997e-24],\n",
       "        [6.9831e-01, 2.0007e-01, 9.4507e-02,  ..., 2.5163e-22, 1.7294e-22,\n",
       "         1.6086e-23]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [0.6983, 0.8984, 0.9929,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([4, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ -9.4589, -43.1378, -43.1378, -43.1378], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([4, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  362],\n",
       "        [11858],\n",
       "        [ 3171],\n",
       "        [ 2038]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.0610e-05, -3.5909e-01, -1.6091e+00, -2.3591e+00], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([4, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224, 11858],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  3171],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ -9.4589, -43.4969, -44.7469, -45.4969], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 7-p\n",
      "data: {\"id\": \"7-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"ation\", \"parent\": 0, \"prob\": 7.799118450478204e-05}, {\"content\": \"elev\", \"parent\": 1, \"prob\": 1.286858130179515e-19}, {\"content\": \"height\", \"parent\": 1, \"prob\": 3.686910491506643e-20}, {\"content\": \"above\", \"parent\": 1, \"prob\": 1.741572991525982e-20}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15405 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([4, 19])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([4])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([4, 19, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([4, 19, 3072])\n",
      "infer - after batch run: GPU memory used: 15405 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([4, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224, 11858],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  3171],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ -9.4589, -43.4969, -44.7469, -45.4969], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "embeddings_np\n",
      "(4, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.2265625 , -1.7265625 ,  1.828125  , ..., -0.35742188,\n",
       "         0.8828125 ,  0.328125  ],\n",
       "       [ 2.125     , -2.265625  ,  2.328125  , ...,  0.8203125 ,\n",
       "         0.359375  , -2.0625    ],\n",
       "       [-1.0546875 , -0.04760742,  1.234375  , ..., -2.640625  ,\n",
       "        -0.08251953, -0.78125   ],\n",
       "       [-2.328125  , -1.921875  ,  2.46875   , ...,  1.109375  ,\n",
       "         0.11474609, -1.1484375 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_space\n",
      "(4, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 42.043888, 100.05355 ],\n",
       "       [ 64.13674 , 105.39813 ],\n",
       "       [ 43.182697, 100.9499  ],\n",
       "       [ 88.62732 ,   0.      ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_clusters\n",
      "(4,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k_mean_logprob_mass\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-97.70274085, -45.49691314])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "closest\n",
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 3]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_aunts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2], [3]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-97.7027, -45.4969], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 8-k\"\n",
      "data: {\"id\": \"8-k\", \"level_type\": \"k_means\", \"nodes\": [{\"content\": \"ation\", \"parent\": 0, \"aunts\": [0, 1, 2], \"prob\": 3.700315724286182e-43}, {\"content\": \"above\", \"parent\": 3, \"aunts\": [3], \"prob\": 1.741572991525982e-20}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-97.7027, -45.4969], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0850, -0.9180, -5.1875,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 1.6797, -1.0234, -9.4375,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9033e-01, 3.1520e-03, 2.1663e-03,  ..., 1.5174e-20, 1.3391e-20,\n",
       "         2.3270e-21],\n",
       "        [1.0000e+00, 8.3153e-07, 5.0435e-07,  ..., 1.6687e-24, 1.1469e-24,\n",
       "         8.9319e-25]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.9903, 0.9935, 0.9956,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([2, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-97.7027, -45.4969], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2038],\n",
       "        [7205]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-9.7195e-03, -2.3842e-06], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362,  2038],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038,  7205]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-97.7125, -45.4969], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 8-p\n",
      "data: {\"id\": \"8-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"above\", \"parent\": 0, \"prob\": 3.66452455770134e-43}, {\"content\": \"sea\", \"parent\": 1, \"prob\": 1.7415688392922036e-20}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "\n",
      "num_batches\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer start: GPU memory used: 15405 MB.\n",
      "\n",
      "batch_candidates\n",
      "torch.Size([2, 20])\n",
      "\n",
      "batch_candidate_logprobs\n",
      "torch.Size([2])\n",
      "\n",
      "batch_logits\n",
      "torch.Size([2, 20, 32064])\n",
      "\n",
      "hidden_states[-1]\n",
      "torch.Size([2, 20, 3072])\n",
      "infer - after batch run: GPU memory used: 15405 MB.\n",
      "\n",
      "candidates\n",
      "torch.Size([2, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362,  2038],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038,  7205]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-97.7125, -45.4969], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "last_tok_logits\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1.5781,  -3.1719, -11.3125,  ...,   0.0000,   0.0000,   0.0000],\n",
       "        [  0.8398,  -5.3438, -11.2500,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sorted_logits\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_indices\n",
      "torch.Size([2, 32064])\n",
      "\n",
      "sorted_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.9999e-01, 1.9947e-06, 1.5535e-06,  ..., 3.3516e-23, 2.9578e-23,\n",
       "         2.3035e-23],\n",
       "        [1.0000e+00, 2.6996e-07, 1.8554e-07,  ..., 4.9401e-28, 3.8473e-28,\n",
       "         5.9001e-29]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cum_probs\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keep_indices\n",
      "torch.Size([2, 32064])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  ..., False, False, False],\n",
       "        [ True, False, False,  ..., False, False, False]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_parents\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidates\n",
      "torch.Size([2, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362,  2038],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038,  7205]],\n",
       "       device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "carryover_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-97.7125, -45.4969], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_toks\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[7205],\n",
       "        [3233]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_tok_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-5.9605e-06, -5.9605e-07], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidates\n",
      "torch.Size([2, 21])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 11858,   362,  2038,\n",
       "          7205],\n",
       "        [    1, 32010,  1724,   338,   278,  9939, 14378, 29973, 29871, 32007,\n",
       "         32001,   450,  9939, 14378,   297,  4958,   310, 19224,  2038,  7205,\n",
       "          3233]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "new_candidate_logprobs\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-97.7125, -45.4969], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event: message\n",
      "id: 9-p\n",
      "data: {\"id\": \"9-p\", \"level_type\": \"top_p\", \"nodes\": [{\"content\": \"sea\", \"parent\": 0, \"prob\": 3.664502715432991e-43}, {\"content\": \"level\", \"parent\": 1, \"prob\": 1.7415678012362957e-20}]}\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n",
      "event: message\n",
      "id: END\n",
      "data: []\n",
      "\n",
      "\n",
      "\n",
      "====================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "it = InferenceTensor()\n",
    "\n",
    "for x in it.candidates_generator(0.9, 2, 'What is the highest mountain?'):\n",
    "    print(x)\n",
    "    print()\n",
    "    print('====================================')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
